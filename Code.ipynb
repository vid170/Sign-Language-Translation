{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b014624a22d34b419da0677f58f54e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26e007169ee94541a7935b1c6e733f9f",
              "IPY_MODEL_d4b2f462c0b94ae3b1276220abaea1ad",
              "IPY_MODEL_805d801839c742d2aca337dcb1b842e7"
            ],
            "layout": "IPY_MODEL_f99b6071fe904d23b9dafdeed13c76f9"
          }
        },
        "26e007169ee94541a7935b1c6e733f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41e7db33acd461c8a015c81952b923f",
            "placeholder": "​",
            "style": "IPY_MODEL_30704a5e30cd47eeac5a4865409c721e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d4b2f462c0b94ae3b1276220abaea1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fa25d2fa61c463a962d6a1a58a78977",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19a0b746897141a6adb8c86fd983d53b",
            "value": 42
          }
        },
        "805d801839c742d2aca337dcb1b842e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d0f962f6004a05a4b272c5c5cf9102",
            "placeholder": "​",
            "style": "IPY_MODEL_0a3100f3fc15422884a26ea9099edf56",
            "value": " 42.0/42.0 [00:00&lt;00:00, 2.86kB/s]"
          }
        },
        "f99b6071fe904d23b9dafdeed13c76f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41e7db33acd461c8a015c81952b923f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30704a5e30cd47eeac5a4865409c721e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fa25d2fa61c463a962d6a1a58a78977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a0b746897141a6adb8c86fd983d53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2d0f962f6004a05a4b272c5c5cf9102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3100f3fc15422884a26ea9099edf56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "196eb1b63b7a4531838ab5380fac1dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d5c4e4a1ed745e48d397642b2cdd899",
              "IPY_MODEL_ba07b5c70c444e46b6f1a445cea6ab59",
              "IPY_MODEL_636aae2326cf4cc29cb21e035f1ff1af"
            ],
            "layout": "IPY_MODEL_0146471abaa040b2a60c826494ec1f5c"
          }
        },
        "9d5c4e4a1ed745e48d397642b2cdd899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dae456056dd7477785cd3d2ec86d2a8a",
            "placeholder": "​",
            "style": "IPY_MODEL_bdd0a6ae27c44689a3148f4de797a4ec",
            "value": "source.spm: 100%"
          }
        },
        "ba07b5c70c444e46b6f1a445cea6ab59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e97acbe479481fa0674773bc770cf9",
            "max": 768489,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_365c6e33475644a885967fa0d7bbcc03",
            "value": 768489
          }
        },
        "636aae2326cf4cc29cb21e035f1ff1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd07dd5ab11455e8c0c431194a8f626",
            "placeholder": "​",
            "style": "IPY_MODEL_979836b00cca43fd97316c16c48b393f",
            "value": " 768k/768k [00:00&lt;00:00, 11.2MB/s]"
          }
        },
        "0146471abaa040b2a60c826494ec1f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae456056dd7477785cd3d2ec86d2a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd0a6ae27c44689a3148f4de797a4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45e97acbe479481fa0674773bc770cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365c6e33475644a885967fa0d7bbcc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cd07dd5ab11455e8c0c431194a8f626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979836b00cca43fd97316c16c48b393f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e87828548e47b3b944bd7a6b69da40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b0d4f144b0844bcafac9c313fb1dd18",
              "IPY_MODEL_95811dd980104397ae53137b68d50b31",
              "IPY_MODEL_1b3c8b8e56f24a9babaf677d5593cd70"
            ],
            "layout": "IPY_MODEL_60a58575f01f4c939a941b0452fc13bf"
          }
        },
        "0b0d4f144b0844bcafac9c313fb1dd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abdd825cedfd4b5584f54a8e5bac95f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ba199aa240164809b3761ce7e1b25fb5",
            "value": "target.spm: 100%"
          }
        },
        "95811dd980104397ae53137b68d50b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_647725d47cb4452e90c32ec7d7223ac1",
            "max": 796845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14eeb86426c9412980e8239bb2e4c2cd",
            "value": 796845
          }
        },
        "1b3c8b8e56f24a9babaf677d5593cd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb8dc65e61784c40881b02691bf70ffa",
            "placeholder": "​",
            "style": "IPY_MODEL_c3b78d9c5fdb4aa9ace98ad852d28a21",
            "value": " 797k/797k [00:00&lt;00:00, 9.92MB/s]"
          }
        },
        "60a58575f01f4c939a941b0452fc13bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abdd825cedfd4b5584f54a8e5bac95f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba199aa240164809b3761ce7e1b25fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "647725d47cb4452e90c32ec7d7223ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14eeb86426c9412980e8239bb2e4c2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb8dc65e61784c40881b02691bf70ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b78d9c5fdb4aa9ace98ad852d28a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "631cb73785754a2fb25e4692d22adbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df4a2128c3b0417d9d58f07f92564b05",
              "IPY_MODEL_baa4da8b83b94f0fbbd3f3ebd4bb0d9e",
              "IPY_MODEL_7a4710b76ff54ae28c3ebd89d07efa4c"
            ],
            "layout": "IPY_MODEL_82421a11dd4d4e0ea9d6769437298bcb"
          }
        },
        "df4a2128c3b0417d9d58f07f92564b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9d8a75c15a450aaa730a2ab2eb6394",
            "placeholder": "​",
            "style": "IPY_MODEL_2ea7ea521acf4b8a8cd083b094377d37",
            "value": "vocab.json: 100%"
          }
        },
        "baa4da8b83b94f0fbbd3f3ebd4bb0d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7241b2573d8406cbc6f179bb0866488",
            "max": 1273232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17a2710d8b0841c58ac0953e31f9f823",
            "value": 1273232
          }
        },
        "7a4710b76ff54ae28c3ebd89d07efa4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49ea5c35d2164452beffbfeda7efd6b9",
            "placeholder": "​",
            "style": "IPY_MODEL_862be8f8b5bb4b51b4570cf0bdeb97a5",
            "value": " 1.27M/1.27M [00:00&lt;00:00, 33.2MB/s]"
          }
        },
        "82421a11dd4d4e0ea9d6769437298bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b9d8a75c15a450aaa730a2ab2eb6394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea7ea521acf4b8a8cd083b094377d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7241b2573d8406cbc6f179bb0866488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a2710d8b0841c58ac0953e31f9f823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49ea5c35d2164452beffbfeda7efd6b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "862be8f8b5bb4b51b4570cf0bdeb97a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3a2790bf2cf47838c513bbf47d7fb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c97f75d78a5b4f88b7783964a00e8595",
              "IPY_MODEL_67ea381f9b264b82b920360f9588ef5d",
              "IPY_MODEL_eb4491b51d0d42e7a1680b068815bed6"
            ],
            "layout": "IPY_MODEL_1bd1f171b4ee475b92036a9977b18a6c"
          }
        },
        "c97f75d78a5b4f88b7783964a00e8595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b7f9d35f7345e497a5f5c0d699ccff",
            "placeholder": "​",
            "style": "IPY_MODEL_d5f50eb8ec5745599bd3daae4c8c123a",
            "value": "config.json: 100%"
          }
        },
        "67ea381f9b264b82b920360f9588ef5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc7ceb045744e54b2642817b538907a",
            "max": 1335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_756d0b71e65c45d6b17d9586f3725e73",
            "value": 1335
          }
        },
        "eb4491b51d0d42e7a1680b068815bed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26b88236d634858948f3d7c23592268",
            "placeholder": "​",
            "style": "IPY_MODEL_eb0b6dde6866464e873b3b66532939d9",
            "value": " 1.33k/1.33k [00:00&lt;00:00, 94.3kB/s]"
          }
        },
        "1bd1f171b4ee475b92036a9977b18a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31b7f9d35f7345e497a5f5c0d699ccff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f50eb8ec5745599bd3daae4c8c123a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcc7ceb045744e54b2642817b538907a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756d0b71e65c45d6b17d9586f3725e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b26b88236d634858948f3d7c23592268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb0b6dde6866464e873b3b66532939d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f26528f8f0c84dde887a6baf8dca1491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ec32d747b68453b886adc8d284fb674",
              "IPY_MODEL_767aa496b59648599f33160224f9b696",
              "IPY_MODEL_9d8645469d9f46778fb91a80b3cae621"
            ],
            "layout": "IPY_MODEL_8e66e57c536040f7b6dc00e4d3dd5016"
          }
        },
        "7ec32d747b68453b886adc8d284fb674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6081884e66f243e49cbd66b3556d0947",
            "placeholder": "​",
            "style": "IPY_MODEL_9a769043aeea4a6f96d6e5a1b3460ecb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "767aa496b59648599f33160224f9b696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_451454104ed742ec9aa0b393a77cd29a",
            "max": 297928209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b89695855584f648681b2a78f2a3f41",
            "value": 297928209
          }
        },
        "9d8645469d9f46778fb91a80b3cae621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_050518f1d42949eca0ffbab6bd713ba4",
            "placeholder": "​",
            "style": "IPY_MODEL_84f17113b73e45ba9b9b341f32131109",
            "value": " 298M/298M [00:02&lt;00:00, 135MB/s]"
          }
        },
        "8e66e57c536040f7b6dc00e4d3dd5016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6081884e66f243e49cbd66b3556d0947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a769043aeea4a6f96d6e5a1b3460ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "451454104ed742ec9aa0b393a77cd29a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b89695855584f648681b2a78f2a3f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "050518f1d42949eca0ffbab6bd713ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f17113b73e45ba9b9b341f32131109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5be35db4e44c49d8b6b6c75ceb12d0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26279ec5501947fe9e5429a69fdf867d",
              "IPY_MODEL_6225d62112d34e03b69f679d5636248d",
              "IPY_MODEL_3eda1fee606249ffbb9a4ce52553f4dc"
            ],
            "layout": "IPY_MODEL_7dc420070d4740a694e50fe7e17b690a"
          }
        },
        "26279ec5501947fe9e5429a69fdf867d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9ceff2f9334bd1a723d8043fe7e628",
            "placeholder": "​",
            "style": "IPY_MODEL_b575d7a9558f4eda88d362e112b04b9a",
            "value": "generation_config.json: 100%"
          }
        },
        "6225d62112d34e03b69f679d5636248d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a7e940875a34cb0acc62925f46a7578",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_962836327dc8426ab01637fd2530b544",
            "value": 293
          }
        },
        "3eda1fee606249ffbb9a4ce52553f4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a54ec67054634a3e935fec62bd968236",
            "placeholder": "​",
            "style": "IPY_MODEL_336772b7c5ec402996b623413f7456c2",
            "value": " 293/293 [00:00&lt;00:00, 7.38kB/s]"
          }
        },
        "7dc420070d4740a694e50fe7e17b690a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9ceff2f9334bd1a723d8043fe7e628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b575d7a9558f4eda88d362e112b04b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a7e940875a34cb0acc62925f46a7578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962836327dc8426ab01637fd2530b544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a54ec67054634a3e935fec62bd968236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336772b7c5ec402996b623413f7456c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7Y7PpPOHUtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deec38bc-6265-4e29-f63d-ba327c8e890a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/text-to-gloss-sign-language-translation-main.zip\n",
            "8f6157cdff80530da3756dd7faa058d57f302703\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/augmented_lemm_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/augmented_lemm_norm_tagged.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/dgs_forward_output_itself.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/dgs_reversed_output.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/dgs_reversed_tagged_output.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/forward_text_lemm_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/forward_text_lemm_norm_tagged.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/ph_forward_output.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/ph_forward_output_itself.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/ph_reversed_output.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/ph_reversed_tagged_output.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_glosses_dev_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_glosses_dev_lower_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_glosses_dev_lower_cleaned_amit.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_glosses_dev_upper.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_glosses_dev_upper_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_sentences_dev_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_sentences_dev_lower_lemm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/dgs_sentences_dev_lower_stem.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/dev/german_dev.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_glosses_test_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_glosses_test_lower_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_glosses_test_lower_cleaned_amit.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_glosses_test_upper.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_glosses_test_upper_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_sentences_test_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_sentences_test_lower_lemm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/dgs_sentences_test_lower_stem.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/test/german_test.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_glosses_train_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_glosses_train_lower_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_glosses_train_lower_cleaned_amit.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_glosses_train_upper.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_glosses_train_upper_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_sentences_train_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_sentences_train_lower_lemm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/dgs_sentences_train_lower_stem.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_dgs/train/german_train.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_dev_glosses.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_glosses_dev_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower_lemm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower_lemm_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower_stem.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_glosses_test_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_lemm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_lemm_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_stem.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_test_glosses.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_glosses_train_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower_lemm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower_lemm_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower_norm.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower_stem.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_train_glosses.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/\n",
            " extracting: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/README.md  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/app.py  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/outputs/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/outputs/SYSTEM_1.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/outputs/SYSTEM_2.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/outputs/samples_SYSTEM_1.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/outputs/samples_SYSTEM_2.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/refs/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/refs/dgs_glosses_test_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/refs/dgs_glosses_test_lower_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/refs/german_test.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/refs/samples_dgs_glosses_test_lower.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/refs/samples_dgs_glosses_test_lower_all_cleaned.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/refs/samples_german_test.txt  \n",
            " extracting: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/DGS_Human_Evaluation/requirements.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/Interface.png  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/README.md  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/app.py  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/outputs/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/outputs/SYSTEM_1.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/outputs/SYSTEM_2.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/outputs/SYSTEM_3.txt  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/refs/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/refs/phoenix_test_glosses_lowercase.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/refs/phoenix_test_sentences_lowercase.txt  \n",
            " extracting: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/Phoenix_Human_Evaluation/requirements.txt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Human Evaluations/README.md  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/LICENSE  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Notebooks/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Notebooks/Data_preprocessing_n_Statistical_analysis.ipynb  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Notebooks/Human_evaluation_results_analysis.ipynb  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/README.md  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/1.Baselines/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/1.Baselines/1_phoenix_bpe_2000  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/1.Baselines/1_phoenix_uni_2000  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/1.Baselines/1_phoenix_word_2000  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/1.Baselines/2_dgs_bpe_5000  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/1.Baselines/2_dgs_uni_5000  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/1.Baselines/2_dgs_word_5000  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/1_1_phoenix_bpe_2000_mix  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/1_2_phoenix_bpe_2000_mixtag  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/1_3_1_phoenix_reserved_traning  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/1_3_2_phoenix_bpe_2000_bt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/1_4_phoenix_bpe_2000_bttag  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/1_5_phoenix_bpe_2000_ft  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/1_6_phoenix_bpe_2000_fttag  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/2_1_dgs_bpe_5000_mix  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/2_2_dgs_bpe_5000_mixtag  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/2_3_1_dgs_reserved_training  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/2_3_2_dgs_bpe_5000_bt  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/2_4_dgs_bpe_5000_bttag  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/2.Data Augmentation/2_5_dgs_bpe_5000_ft  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/3.With monolingual dataset/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/3.With monolingual dataset/1_phoenix_mono_bpe_32k  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/3.With monolingual dataset/2_dgs_mono_bpe_32k  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/3.With monolingual dataset/valid.sh  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/3.With monolingual dataset/valid_dgs.sh  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/\n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/dgs_test  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/signdev.bpe.de  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/signdev.bpe.en  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/signtest.bpe.de  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/signtest.bpe.en  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/signtrain.bpe.de  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/signtrain.bpe.en  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/vocab.dede.yml  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/vocab.yml  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/dgs_transfer_cold/vocab_dgs.yml  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/ph_vocab.yml  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/signdev.bpe.de  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/signdev.bpe.en  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/signtest.bpe.de  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/signtest.bpe.en  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/signtrain.bpe.de  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/signtrain.bpe.en  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/transfer_retake  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Fine-tune/phoenix_transfer_cold/vocab.tran.yml  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/1_1_phoenix_pre_training_warm  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/1_2_phoenix_transfer  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/2_1_dgs_pre_training_warm  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/2_2_dgs_transfer  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/valid.sh  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/valid_de.sh  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/4.Transfer Learning/Warm_start/valid_dgs.sh  \n",
            "   creating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/5.Multilingual NMT/\n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/5.Multilingual NMT/1_phoenix_multi_bpe_32k  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/5.Multilingual NMT/1_phoenix_multi_bpe_32k_big  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/5.Multilingual NMT/2_dgs_multi_bpe_32k  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/5.Multilingual NMT/2_dgs_multi_bpe_32k_big  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/5.Multilingual NMT/valid.sh  \n",
            "  inflating: /content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Training Scripts/5.Multilingual NMT/valid_dgs.sh  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/text-to-gloss-sign-language-translation-main.zip -d /content/text-to-gloss-sign-language-translation-main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q sacremoses\n",
        "!pip install -q nltk\n",
        "!pip install -q sacrebleu"
      ],
      "metadata": {
        "id": "DldCuOkzI7i3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e830f04b-92e1-4eed-9af8-c26126e4758b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer, AdamW, MarianConfig,get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "KQzxbIECGw9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline and back + tag"
      ],
      "metadata": {
        "id": "GiyqnL2hLazP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nomal preprocessed text"
      ],
      "metadata": {
        "id": "Gz7-JS4MF4Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to your source and target files\n",
        "source_file_path_train = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower_lemm_norm.txt'\n",
        "target_file_path_train = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_glosses_train_lower.txt'\n",
        "\n",
        "source_file_path_valid='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower_lemm_norm.txt'\n",
        "target_file_path_valid='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_glosses_dev_lower.txt'\n",
        "\n",
        "source_file_path_test='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_lemm_norm.txt'\n",
        "target_file_path_test='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_glosses_test_lower.txt'\n",
        "# Initialize lists to store source and target sentences\n"
      ],
      "metadata": {
        "id": "F8U_SSdTBynj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_train, 'r') as file:\n",
        "    train_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_train, 'r') as file:\n",
        "    train_dataset_tgt = file.readlines()"
      ],
      "metadata": {
        "id": "DSkebjlDIEJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "back+tag text"
      ],
      "metadata": {
        "id": "Cb20C9x0F99H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_backtag_train = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/synthetic data/ph_reversed_tagged_output.txt'"
      ],
      "metadata": {
        "id": "okDdEEywGBf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_train, 'r') as file:\n",
        "    train_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_train, 'r') as file:\n",
        "    train_dataset_tgt = file.readlines()\n",
        "\n",
        "with open(src_backtag_train, 'r') as file:\n",
        "    train_backtag_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_train, 'r') as file:\n",
        "    train_backtag_tgt = file.readlines()\n",
        "\n",
        "train_dataset_src = train_dataset_src+ train_backtag_src\n",
        "train_dataset_tgt = train_dataset_tgt+ train_backtag_tgt\n",
        "\n",
        "\n",
        "print(len(train_dataset_src),\" \", len(train_dataset_tgt))\n",
        "print(train_dataset_src[0],\"--> \", train_dataset_tgt[0])\n",
        "print(train_dataset_src[7096],\"--> \", train_dataset_tgt[7096])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIjSfDv5ILi-",
        "outputId": "01e9e65d-71f4-4d7f-dc8e-3161ba0bc4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14192   14192\n",
            "und nun die wettervorhersage fuer morgen donnerstag den zwoelf august\n",
            " -->  jetzt wetter morgen donnerstag zwoelf februar\n",
            "\n",
            "<BT> und nun die wettervorhersage fuer morgen donnerstag den zwoelf februar\n",
            " -->  jetzt wetter morgen donnerstag zwoelf februar\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_valid, 'r') as file:\n",
        "    valid_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_valid, 'r') as file:\n",
        "    valid_dataset_tgt = file.readlines()"
      ],
      "metadata": {
        "id": "A0IXkfNVCWK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset_src[1])\n",
        "print(train_dataset_tgt[1])\n",
        "print(len(train_dataset_src), len(train_dataset_tgt))\n",
        "print(len(valid_dataset_src), len(valid_dataset_tgt))"
      ],
      "metadata": {
        "id": "094f8dKXDYwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8244408-333c-4d37-efda-0c77b9e1c00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mancherorts regnen es auch lang und ergiebig auch lokal ueberschwemmung sein wieder moeglich\n",
            "\n",
            "ort regen durch regen koennen ueberschwemmung koennen\n",
            "\n",
            "14192 14192\n",
            "519 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "wLwotX9TYgUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model name\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-de'  # Replace with your desired Marian model\n",
        "\n",
        "sentencepiece_options = \"model_type=bpe,vocab_size=2000\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name, additional_special_tokens=[\"<s>\", \"</s>\", \"<pad>\", \"<unk>\"], sentencepiece_options=sentencepiece_options)\n",
        "tokenizer.model_max_length = 512  # Adjust as needed\n",
        "\n",
        "# Apply additional configurations\n",
        "config = MarianConfig.from_pretrained(model_name)\n",
        "config.layer_norm = True  # Set layer normalization to True\n",
        "config.dim_emb = 512\n",
        "config.transformer_dim_ffn = 2048\n",
        "config.transformer_heads = 8\n",
        "config.transformer_ffn_activation = \"relu\"\n",
        "config.enc_depth = 1\n",
        "config.dec_depth = 2\n",
        "config.enc_cell = \"lstm\"\n",
        "config.enc_cell_depth = 2\n",
        "config.dec_cell_base_depth = 2\n",
        "config.dec_cell = \"lstm\"\n",
        "config.sync_sgd = True\n",
        "config.dropout_src = 0.1\n",
        "config.dropout_trg = 0.1\n",
        "config.optimizer_params = [0.9, 0.98, 1e-09]\n",
        "config.clip_norm = 5\n",
        "config.beam_size = 6\n",
        "config.normalize = 0.6\n",
        "config.exponential_smoothing = True\n",
        "config.seed = 1111\n",
        "config.tied_embeddings_all = True\n",
        "config.transformer_dropout = 0.1\n",
        "config.label_smoothing = 0.1\n",
        "\n",
        "# Load the model with modified tokenizer\n",
        "model = MarianMTModel.from_pretrained(model_name, config=config)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "4_Zpr75c4qa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "b014624a22d34b419da0677f58f54e19",
            "26e007169ee94541a7935b1c6e733f9f",
            "d4b2f462c0b94ae3b1276220abaea1ad",
            "805d801839c742d2aca337dcb1b842e7",
            "f99b6071fe904d23b9dafdeed13c76f9",
            "e41e7db33acd461c8a015c81952b923f",
            "30704a5e30cd47eeac5a4865409c721e",
            "1fa25d2fa61c463a962d6a1a58a78977",
            "19a0b746897141a6adb8c86fd983d53b",
            "d2d0f962f6004a05a4b272c5c5cf9102",
            "0a3100f3fc15422884a26ea9099edf56",
            "196eb1b63b7a4531838ab5380fac1dff",
            "9d5c4e4a1ed745e48d397642b2cdd899",
            "ba07b5c70c444e46b6f1a445cea6ab59",
            "636aae2326cf4cc29cb21e035f1ff1af",
            "0146471abaa040b2a60c826494ec1f5c",
            "dae456056dd7477785cd3d2ec86d2a8a",
            "bdd0a6ae27c44689a3148f4de797a4ec",
            "45e97acbe479481fa0674773bc770cf9",
            "365c6e33475644a885967fa0d7bbcc03",
            "7cd07dd5ab11455e8c0c431194a8f626",
            "979836b00cca43fd97316c16c48b393f",
            "c1e87828548e47b3b944bd7a6b69da40",
            "0b0d4f144b0844bcafac9c313fb1dd18",
            "95811dd980104397ae53137b68d50b31",
            "1b3c8b8e56f24a9babaf677d5593cd70",
            "60a58575f01f4c939a941b0452fc13bf",
            "abdd825cedfd4b5584f54a8e5bac95f0",
            "ba199aa240164809b3761ce7e1b25fb5",
            "647725d47cb4452e90c32ec7d7223ac1",
            "14eeb86426c9412980e8239bb2e4c2cd",
            "fb8dc65e61784c40881b02691bf70ffa",
            "c3b78d9c5fdb4aa9ace98ad852d28a21",
            "631cb73785754a2fb25e4692d22adbef",
            "df4a2128c3b0417d9d58f07f92564b05",
            "baa4da8b83b94f0fbbd3f3ebd4bb0d9e",
            "7a4710b76ff54ae28c3ebd89d07efa4c",
            "82421a11dd4d4e0ea9d6769437298bcb",
            "9b9d8a75c15a450aaa730a2ab2eb6394",
            "2ea7ea521acf4b8a8cd083b094377d37",
            "e7241b2573d8406cbc6f179bb0866488",
            "17a2710d8b0841c58ac0953e31f9f823",
            "49ea5c35d2164452beffbfeda7efd6b9",
            "862be8f8b5bb4b51b4570cf0bdeb97a5",
            "b3a2790bf2cf47838c513bbf47d7fb38",
            "c97f75d78a5b4f88b7783964a00e8595",
            "67ea381f9b264b82b920360f9588ef5d",
            "eb4491b51d0d42e7a1680b068815bed6",
            "1bd1f171b4ee475b92036a9977b18a6c",
            "31b7f9d35f7345e497a5f5c0d699ccff",
            "d5f50eb8ec5745599bd3daae4c8c123a",
            "dcc7ceb045744e54b2642817b538907a",
            "756d0b71e65c45d6b17d9586f3725e73",
            "b26b88236d634858948f3d7c23592268",
            "eb0b6dde6866464e873b3b66532939d9",
            "f26528f8f0c84dde887a6baf8dca1491",
            "7ec32d747b68453b886adc8d284fb674",
            "767aa496b59648599f33160224f9b696",
            "9d8645469d9f46778fb91a80b3cae621",
            "8e66e57c536040f7b6dc00e4d3dd5016",
            "6081884e66f243e49cbd66b3556d0947",
            "9a769043aeea4a6f96d6e5a1b3460ecb",
            "451454104ed742ec9aa0b393a77cd29a",
            "1b89695855584f648681b2a78f2a3f41",
            "050518f1d42949eca0ffbab6bd713ba4",
            "84f17113b73e45ba9b9b341f32131109",
            "5be35db4e44c49d8b6b6c75ceb12d0f2",
            "26279ec5501947fe9e5429a69fdf867d",
            "6225d62112d34e03b69f679d5636248d",
            "3eda1fee606249ffbb9a4ce52553f4dc",
            "7dc420070d4740a694e50fe7e17b690a",
            "ed9ceff2f9334bd1a723d8043fe7e628",
            "b575d7a9558f4eda88d362e112b04b9a",
            "4a7e940875a34cb0acc62925f46a7578",
            "962836327dc8426ab01637fd2530b544",
            "a54ec67054634a3e935fec62bd968236",
            "336772b7c5ec402996b623413f7456c2"
          ]
        },
        "outputId": "0ee70354-3501-47e3-8d26-55c9292e1eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b014624a22d34b419da0677f58f54e19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "196eb1b63b7a4531838ab5380fac1dff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e87828548e47b3b944bd7a6b69da40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "631cb73785754a2fb25e4692d22adbef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3a2790bf2cf47838c513bbf47d7fb38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f26528f8f0c84dde887a6baf8dca1491"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5be35db4e44c49d8b6b6c75ceb12d0f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(58102, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_texts = train_dataset_src\n",
        "target_texts = train_dataset_tgt\n",
        "\n",
        "source_texts_val = valid_dataset_src\n",
        "target_texts_val = valid_dataset_tgt"
      ],
      "metadata": {
        "id": "uPU5WqD6JAYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(source_texts[1])\n",
        "print(target_texts[1])\n",
        "print(len(source_texts), len(target_texts))\n",
        "print(len(source_texts_val), len(target_texts_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0w6AGGFJRGr",
        "outputId": "58a443cd-bc52-4e89-f39c-57d6b3453f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mancherorts regnen es auch lang und ergiebig auch lokal ueberschwemmung sein wieder moeglich\n",
            "\n",
            "ort regen durch regen koennen ueberschwemmung koennen\n",
            "\n",
            "14192 14192\n",
            "519 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize source and target sentences\n",
        "tokenized_data_train = tokenizer(source_texts, text_target=target_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_train = tokenized_data_train['input_ids']\n",
        "attention_mask_train = tokenized_data_train['attention_mask']\n",
        "labels_train = tokenized_data_train['labels']\n",
        "\n",
        "tokenized_data_valid = tokenizer(source_texts_val, text_target=target_texts_val, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_valid = tokenized_data_valid['input_ids']\n",
        "attention_mask_valid = tokenized_data_valid['attention_mask']\n",
        "labels_valid = tokenized_data_valid['labels']\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "train_dataset = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(input_ids_valid, attention_mask_valid, labels_valid)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "id": "aPiYjWM8Bw0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##normal preprocessing result"
      ],
      "metadata": {
        "id": "de0qrxnuUww1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch =10"
      ],
      "metadata": {
        "id": "Ekv9__zrUciA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using sacrebleu"
      ],
      "metadata": {
        "id": "dmR8gMTSUW2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sacrebleu import corpus_bleu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "num_epochs = 10\n",
        "warmup_steps = 16000  # Number of warmup steps\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    references = []  # To store actual target sentences\n",
        "    translations = []  # To store translated sentences\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            val_input_ids, val_attention_mask, val_labels = [val_b.to(device) for val_b in val_batch]\n",
        "\n",
        "            val_outputs = model.generate(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
        "            decoded_outputs = tokenizer.batch_decode(val_outputs, skip_special_tokens=True)\n",
        "\n",
        "            # Append actual target sentences and translations\n",
        "            references.extend([tokenizer.decode(t, skip_special_tokens=True) for t in val_labels.cpu().numpy()])\n",
        "            translations.extend(decoded_outputs)\n",
        "    # Compute BLEU score\n",
        "    bleu_score = corpus_bleu(translations,[references])\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation BLEU Score: {bleu_score.score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782e3feb-ae3b-482c-9923-1413e044900c",
        "id": "sGnasU4zUU8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Average Loss: 1.9136\n",
            "Epoch [1/10] - Validation BLEU Score: 1.26\n",
            "Epoch [2/10] - Average Loss: 0.6154\n",
            "Epoch [2/10] - Validation BLEU Score: 5.85\n",
            "Epoch [3/10] - Average Loss: 0.4802\n",
            "Epoch [3/10] - Validation BLEU Score: 17.28\n",
            "Epoch [4/10] - Average Loss: 0.4166\n",
            "Epoch [4/10] - Validation BLEU Score: 22.40\n",
            "Epoch [5/10] - Average Loss: 0.3761\n",
            "Epoch [5/10] - Validation BLEU Score: 22.60\n",
            "Epoch [6/10] - Average Loss: 0.3451\n",
            "Epoch [6/10] - Validation BLEU Score: 23.96\n",
            "Epoch [7/10] - Average Loss: 0.3201\n",
            "Epoch [7/10] - Validation BLEU Score: 22.12\n",
            "Epoch [8/10] - Average Loss: 0.3006\n",
            "Epoch [8/10] - Validation BLEU Score: 22.21\n",
            "Epoch [9/10] - Average Loss: 0.2787\n",
            "Epoch [9/10] - Validation BLEU Score: 25.25\n",
            "Epoch [10/10] - Average Loss: 0.2588\n",
            "Epoch [10/10] - Validation BLEU Score: 25.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translations[3])\n",
        "references[3]\n"
      ],
      "metadata": {
        "id": "mozvgnFgKFYA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "618997d5-f8b9-47f8-ee7b-553d90b92384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mittwoch ix regen nordwest wehen kueste stark wehen\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mittwoch regen koennen nordwest wahrscheinlich nord stark wind'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###test dataset"
      ],
      "metadata": {
        "id": "UOxtg_UpDZ-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_test, 'r') as file:\n",
        "    test_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_test, 'r') as file:\n",
        "    test_dataset_tgt = file.readlines()\n",
        "\n",
        "\n",
        "tokenized_data_test = tokenizer(test_dataset_src, text_target=test_dataset_tgt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_test = tokenized_data_test['input_ids']\n",
        "attention_mask_test = tokenized_data_test['attention_mask']\n",
        "labels_test = tokenized_data_test['labels']\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "test_dataset = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "model.eval()\n",
        "references_test = []  # To store actual target sentences for the test set\n",
        "translations_test = []  # To store translated sentences for the test set\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_batch in test_loader:\n",
        "        test_input_ids, test_attention_mask, test_labels = [test_b.to(device) for test_b in test_batch]\n",
        "\n",
        "        test_outputs = model.generate(input_ids=test_input_ids, attention_mask=test_attention_mask)\n",
        "        decoded_test_outputs = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)\n",
        "\n",
        "        # Append actual target sentences and translations for the test set\n",
        "        references_test.extend([tokenizer.decode(t, skip_special_tokens=True) for t in test_labels.cpu().numpy()])\n",
        "        translations_test.extend(decoded_test_outputs)\n",
        "\n",
        "# Compute BLEU score for the test dataset\n",
        "bleu_score_test = corpus_bleu(translations_test,[references_test])\n",
        "print(f\"Test BLEU Score: {bleu_score_test.score :.2f}\")"
      ],
      "metadata": {
        "id": "R43YTjG5Tu6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733662f2-534f-417a-84f9-fb9a3cb83a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test BLEU Score: 22.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##back+tag result"
      ],
      "metadata": {
        "id": "L08YwT0uU2Tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch =5"
      ],
      "metadata": {
        "id": "LtmUhsumU2Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sacrebleu import corpus_bleu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "num_epochs = 4\n",
        "warmup_steps = 16000  # Number of warmup steps\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    references = []  # To store actual target sentences\n",
        "    translations = []  # To store translated sentences\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            val_input_ids, val_attention_mask, val_labels = [val_b.to(device) for val_b in val_batch]\n",
        "\n",
        "            val_outputs = model.generate(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
        "            decoded_outputs = tokenizer.batch_decode(val_outputs, skip_special_tokens=True)\n",
        "\n",
        "            # Append actual target sentences and translations\n",
        "            references.extend([tokenizer.decode(t, skip_special_tokens=True) for t in val_labels.cpu().numpy()])\n",
        "            translations.extend(decoded_outputs)\n",
        "    # Compute BLEU score\n",
        "    bleu_score = corpus_bleu(translations,[references])\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation BLEU Score: {bleu_score.score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58c6666-4b65-4acd-bd06-115801d27dd6",
        "id": "E0ofumwTU2Ts"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/4] - Average Loss: 1.2846\n",
            "Epoch [1/4] - Validation BLEU Score: 6.17\n",
            "Epoch [2/4] - Average Loss: 0.4584\n",
            "Epoch [2/4] - Validation BLEU Score: 21.99\n",
            "Epoch [3/4] - Average Loss: 0.3757\n",
            "Epoch [3/4] - Validation BLEU Score: 22.04\n",
            "Epoch [4/4] - Average Loss: 0.3314\n",
            "Epoch [4/4] - Validation BLEU Score: 23.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sacrebleu import corpus_bleu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "num_epochs = 1\n",
        "warmup_steps = 16000  # Number of warmup steps\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    references = []  # To store actual target sentences\n",
        "    translations = []  # To store translated sentences\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            val_input_ids, val_attention_mask, val_labels = [val_b.to(device) for val_b in val_batch]\n",
        "\n",
        "            val_outputs = model.generate(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
        "            decoded_outputs = tokenizer.batch_decode(val_outputs, skip_special_tokens=True)\n",
        "\n",
        "            # Append actual target sentences and translations\n",
        "            references.extend([tokenizer.decode(t, skip_special_tokens=True) for t in val_labels.cpu().numpy()])\n",
        "            translations.extend(decoded_outputs)\n",
        "    # Compute BLEU score\n",
        "    bleu_score = corpus_bleu(translations,[references])\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation BLEU Score: {bleu_score.score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyWb6vv4zhqh",
        "outputId": "b59decff-0f90-4250-db31-5426564433f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1] - Average Loss: 0.2675\n",
            "Epoch [1/1] - Validation BLEU Score: 26.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translations[3])\n",
        "references[3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4989eb95-09bd-439f-bb9f-1ed00c81b2d2",
        "id": "AVQGYDTYU2Tt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mittwoch ix regen nordwest kueste stark regen\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mittwoch regen koennen nordwest wahrscheinlich nord stark wind'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###test dataset"
      ],
      "metadata": {
        "id": "i06lzCUkU2Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_test, 'r') as file:\n",
        "    test_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_test, 'r') as file:\n",
        "    test_dataset_tgt = file.readlines()\n",
        "\n",
        "\n",
        "tokenized_data_test = tokenizer(test_dataset_src, text_target=test_dataset_tgt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_test = tokenized_data_test['input_ids']\n",
        "attention_mask_test = tokenized_data_test['attention_mask']\n",
        "labels_test = tokenized_data_test['labels']\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "test_dataset = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "model.eval()\n",
        "references_test = []  # To store actual target sentences for the test set\n",
        "translations_test = []  # To store translated sentences for the test set\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_batch in test_loader:\n",
        "        test_input_ids, test_attention_mask, test_labels = [test_b.to(device) for test_b in test_batch]\n",
        "\n",
        "        test_outputs = model.generate(input_ids=test_input_ids, attention_mask=test_attention_mask)\n",
        "        decoded_test_outputs = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)\n",
        "\n",
        "        # Append actual target sentences and translations for the test set\n",
        "        references_test.extend([tokenizer.decode(t, skip_special_tokens=True) for t in test_labels.cpu().numpy()])\n",
        "        translations_test.extend(decoded_test_outputs)\n",
        "\n",
        "# Compute BLEU score for the test dataset\n",
        "bleu_score_test = corpus_bleu(translations_test,[references_test])\n",
        "print(f\"Test BLEU Score: {bleu_score_test.score :.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zBFZE_T0pjE",
        "outputId": "ad819278-c5e5-4bf4-95ad-88e08129a2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test BLEU Score: 21.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Syntax aware transformer"
      ],
      "metadata": {
        "id": "1J8O-QkbLRKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "JYmpvtV-i_t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "source_texts_val_pos = []\n",
        "\n",
        "for sentence in source_texts_val:\n",
        "  tokens = nltk.word_tokenize(sentence)\n",
        "  pos_tags = nltk.pos_tag(tokens)\n",
        "  sent = ''\n",
        "  for tup in pos_tags:\n",
        "    sent = sent +\" \"+ tup[1]\n",
        "    # print(tup[1])\n",
        "  source_texts_val_pos.append(sent)\n",
        "  # print(sent)\n",
        "# source_texts_val_pos\n",
        "\n",
        "\n",
        "source_texts_pos = []\n",
        "\n",
        "for sentence in source_texts:\n",
        "  tokens = nltk.word_tokenize(sentence)\n",
        "  pos_tags = nltk.pos_tag(tokens)\n",
        "  sent = ''\n",
        "  for tup in pos_tags:\n",
        "    sent = sent +\" \"+ tup[1]\n",
        "    # print(tup[1])\n",
        "  source_texts_pos.append(sent)"
      ],
      "metadata": {
        "id": "heIzkxCnjVJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac975014-465a-4e4e-91a5-cb424013013a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize source and target sentences\n",
        "tokenized_data_train_pos = tokenizer(source_texts_pos, text_target=target_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_train_pos = tokenized_data_train_pos['input_ids']\n",
        "attention_mask_train_pos = tokenized_data_train_pos['attention_mask']\n",
        "labels_train_pos = tokenized_data_train_pos['labels']"
      ],
      "metadata": {
        "id": "f8PQ0IQWtDnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data_valid_pos = tokenizer(source_texts_val_pos, text_target=target_texts_val, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_valid_pos = tokenized_data_valid_pos['input_ids']\n",
        "attention_mask_valid_pos = tokenized_data_valid_pos['attention_mask']\n",
        "labels_valid_pos = tokenized_data_valid_pos['labels']\n",
        "\n",
        "input_ids_train = torch.cat([input_ids_train, input_ids_train_pos], dim=1)\n",
        "attention_mask_train = torch.cat([attention_mask_train, attention_mask_train_pos], dim=1)\n",
        "labels_train = torch.cat([labels_train, labels_train_pos], dim=1)\n",
        "\n",
        "input_ids_valid = torch.cat([input_ids_valid, input_ids_valid_pos], dim=1)\n",
        "attention_mask_valid = torch.cat([attention_mask_valid, attention_mask_valid_pos], dim=1)\n",
        "labels_valid = torch.cat([labels_valid, labels_valid_pos], dim=1)\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "train_dataset = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(input_ids_valid, attention_mask_valid, labels_valid)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "bfd4fqlrtRIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sacrebleu import corpus_bleu\n",
        "\n",
        "# Training the model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "num_epochs = 10\n",
        "warmup_steps = 16000  # Number of warmup steps\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    references = []  # To store actual target sentences\n",
        "    translations = []  # To store translated sentences\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            val_input_ids, val_attention_mask, val_labels = [val_b.to(device) for val_b in val_batch]\n",
        "\n",
        "            val_outputs = model.generate(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
        "            decoded_outputs = tokenizer.batch_decode(val_outputs, skip_special_tokens=True)\n",
        "\n",
        "            # Append actual target sentences and translations\n",
        "            references.extend([tokenizer.decode(t, skip_special_tokens=True) for t in val_labels.cpu().numpy()])\n",
        "            translations.extend(decoded_outputs)\n",
        "\n",
        "    # Compute BLEU score\n",
        "    bleu_score = corpus_bleu(translations,[references])\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation BLEU Score: {bleu_score.score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tASsHcIB8WE0",
        "outputId": "d0d0c294-9bd3-4027-8e4e-e3aa5c370866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Average Loss: 1.0729\n",
            "Epoch [1/10] - Validation BLEU Score: 3.13\n",
            "Epoch [2/10] - Average Loss: 0.2734\n",
            "Epoch [2/10] - Validation BLEU Score: 9.49\n",
            "Epoch [3/10] - Average Loss: 0.2072\n",
            "Epoch [3/10] - Validation BLEU Score: 11.86\n",
            "Epoch [4/10] - Average Loss: 0.1799\n",
            "Epoch [4/10] - Validation BLEU Score: 13.33\n",
            "Epoch [5/10] - Average Loss: 0.1609\n",
            "Epoch [5/10] - Validation BLEU Score: 16.40\n",
            "Epoch [6/10] - Average Loss: 0.1450\n",
            "Epoch [6/10] - Validation BLEU Score: 18.02\n",
            "Epoch [7/10] - Average Loss: 0.1310\n",
            "Epoch [7/10] - Validation BLEU Score: 20.64\n",
            "Epoch [8/10] - Average Loss: 0.1172\n",
            "Epoch [8/10] - Validation BLEU Score: 22.98\n",
            "Epoch [9/10] - Average Loss: 0.1035\n",
            "Epoch [9/10] - Validation BLEU Score: 24.88\n",
            "Epoch [10/10] - Average Loss: 0.0919\n",
            "Epoch [10/10] - Validation BLEU Score: 25.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_test, 'r') as file:\n",
        "    test_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_test, 'r') as file:\n",
        "    test_dataset_tgt = file.readlines()\n",
        "\n",
        "test_dataset_src_pos = []\n",
        "\n",
        "for sentence in test_dataset_src_pos:\n",
        "  tokens = nltk.word_tokenize(sentence)\n",
        "  pos_tags = nltk.pos_tag(tokens)\n",
        "  sent = ''\n",
        "  for tup in pos_tags:\n",
        "    sent = sent +\" \"+ tup[1]\n",
        "  test_dataset_src_pos.append(sent)\n",
        "\n",
        "tokenized_data_test = tokenizer(test_dataset_src, text_target=test_dataset_tgt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_test = tokenized_data_test['input_ids']\n",
        "attention_mask_test = tokenized_data_test['attention_mask']\n",
        "labels_test = tokenized_data_test['labels']\n",
        "\n",
        "tokenized_data_test_pos = tokenizer(test_dataset_src_pos, text_target=test_dataset_tgt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_test_pos = tokenized_data_test_pos['input_ids']\n",
        "attention_mask_test_pos = tokenized_data_test_pos['attention_mask']\n",
        "labels_test_pos = tokenized_data_test_pos['labels']\n",
        "\n",
        "input_ids_test = torch.cat([input_ids_test, input_ids_test_pos], dim=1)\n",
        "attention_mask_test = torch.cat([attention_mask_test, attention_mask_test_pos], dim=1)\n",
        "labels_test = torch.cat([labels_test, labels_test_pos], dim=1)\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "test_dataset = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "model.eval()\n",
        "references_test = []  # To store actual target sentences for the test set\n",
        "translations_test = []  # To store translated sentences for the test set\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_batch in test_loader:\n",
        "        test_input_ids, test_attention_mask, test_labels = [test_b.to(device) for test_b in test_batch]\n",
        "\n",
        "        test_outputs = model.generate(input_ids=test_input_ids, attention_mask=test_attention_mask)\n",
        "        decoded_test_outputs = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)\n",
        "\n",
        "        # Append actual target sentences and translations for the test set\n",
        "        references_test.extend([tokenizer.decode(t, skip_special_tokens=True) for t in test_labels.cpu().numpy()])\n",
        "        translations_test.extend(decoded_test_outputs)\n",
        "\n",
        "# Compute BLEU score for the test dataset\n",
        "bleu_score_test = corpus_bleu(translations_test,[references_test])\n",
        "print(f\"Test BLEU Score: {bleu_score_test.score :.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HVKbFHfm0gw",
        "outputId": "9f193c72-f392-46ca-b4d3-0cfd7bc25787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test BLEU Score: 24.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BART"
      ],
      "metadata": {
        "id": "XUs0qIz_jEzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to your source and target files\n",
        "SRC_TRAIN_FILENAME = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower_lemm_norm.txt'\n",
        "TGT_TRAIN_FILENAME = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_glosses_train_lower.txt'\n",
        "\n",
        "SRC_EVAL_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower_lemm_norm.txt'\n",
        "TGT_EVAL_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_glosses_dev_lower.txt'\n",
        "\n",
        "GEN_SRC_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_lemm_norm.txt'\n",
        "GEN_TGT_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_glosses_test_lower.txt'\n",
        "# Initialize lists to store source and target sentences"
      ],
      "metadata": {
        "id": "aMaPGhIjNkFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_MAPPER = {'amod': 0, 'conj': 1, 'nsubj': 2, 'rs': 3, 'neg': 4, 'appos': 5, 'da': 6, 'pcomp': 7, 'nmod': 8, 'xcomp': 9, 'fixed': 10, 'dative': 11, 'npadvmod': 12, 'predet': 13, 'ac': 14, 'parataxis': 15, 'csubjpass': 16, 'dm': 17, 'pm': 18, 'og': 19, 'flat': 20, 'sb': 21, 'oc': 22, 'op': 23, 'par': 24, 'prep': 25, 'nmc': 26, 'vo': 27, 'obj': 28, 'ag': 29, 'advmod': 30, 'attr': 31, 'ep': 32, 'csubj': 33, 'case': 34, 'aux': 35, 'mark': 36, 'ju': 37, 'nsubjpass': 38, 'uc': 39, 'nk': 40, 'poss': 41, 'dep': 42, 'cc': 43, 'cd': 44, 'compound': 45, 'ph': 46, 'iobj': 47, 'relcl': 48, 'det': 49, 'dobj': 50, 'expl:pass': 51, 'nummod': 52, 'cm': 53, 'expl': 54, 'ams': 55, 'quantmod': 56, 'mnr': 57, 'mo': 58, 'agent': 59, 'acl': 60, 'svp': 61, 'punct': 62, 'ng': 63, 'obl': 64, 'app': 65, 'cop': 66, 'meta': 67, 'rc': 68, 'ROOT': 69, 'cvc': 70, 'pobj': 71, 'preconj': 72, 'cj': 73, 'pd': 74, 'pg': 75, 're': 76, 'oa': 77, 'auxpass': 78, 'acomp': 79, 'advcl': 80, 'pnc': 81, 'adc': 82, 'avc': 83, 'cp': 84, 'ccomp': 85, 'intj': 86, 'prt': 87, 'sbp': 88, 'oprd': 89}"
      ],
      "metadata": {
        "id": "_hbatMMIN7SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install data_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xb7YmNXOMEd",
        "outputId": "47285c6c-6cc5-422a-bf10-28bcf64c4c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting data_generator\n",
            "  Downloading Data_Generator-1.0.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from data_generator) (4.66.1)\n",
            "Collecting XlsxWriter (from data_generator)\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tomlkit (from data_generator)\n",
            "  Downloading tomlkit-0.12.3-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from data_generator) (7.4.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->data_generator) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->data_generator) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->data_generator) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->data_generator) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->data_generator) (2.0.1)\n",
            "Installing collected packages: XlsxWriter, tomlkit, data_generator\n",
            "Successfully installed XlsxWriter-3.1.9 data_generator-1.0.1 tomlkit-0.12.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#%%############################################################################\n",
        "'''                     USEFUL MAPPINGS FOR TOKENIZATION                    '''\n",
        "###############################################################################\n",
        "\n",
        "'''                 DICTIONARY TO MAP SYNTAX INFO TO TOKENS                 '''\n",
        "SYNTAX_MAPPER = {\n",
        "    'CC' :      0, #coordinating conjunction\n",
        "    'CD' :      1, #cardinal digit\n",
        "    'DT' :      2, #determiner\n",
        "    'EX' :      3, #existential there (like: “there is” … think of it like “there exists”)\n",
        "    'FW' :      4, #foreign word\n",
        "    'IN' :      5, #preposition/subordinating conjunction\n",
        "    'JJ' :      6, #adjective ‘big’\n",
        "    'JJR':      7, #adjective, comparative ‘bigger’\n",
        "    'JJS':      8, #adjective, superlative ‘biggest’\n",
        "    'LS' :      9, #list marker 1)\n",
        "    'MD' :      10, #modal could, will\n",
        "    'NN' :      11, #noun, singular ‘desk’\n",
        "    'NNS':      12, #noun plural ‘desks’\n",
        "    'NNP':      13, #proper noun, singular ‘Harrison’\n",
        "    'NNPS':     14, #proper noun, plural ‘Americans’\n",
        "    'PDT' :     15, #predeterminer ‘all the kids’\n",
        "    'POS' :     16, #possessive ending parent’s\n",
        "    'PRP' :     17, #personal pronoun I, he, she\n",
        "    'PRP$':     18, #possessive pronoun my, his, hers\n",
        "    'RB'  :     19, #adverb very, silently,\n",
        "    'RBR' :     20, #adverb, comparative better\n",
        "    'RBS' :     21, #adverb, superlative best\n",
        "    'RP'  :     22, #particle give up\n",
        "    'TO'  :     23, # to go ‘to’ the store.\n",
        "    'UH'  :     24, #interjection, errrrrrrrm\n",
        "    'VB'  :     25, #verb, base form take\n",
        "    'VBD' :     26, #verb, past tense took\n",
        "    'VBG' :     27, #verb, gerund/present participle taking\n",
        "    'VBN' :     28, #verb, past participle taken\n",
        "    'VBP' :     29, #verb, sing. present, non-3d take\n",
        "    'VBZ' :     30, #verb, 3rd person sing. present takes\n",
        "    'WDT' :     31, #wh-determiner which\n",
        "    'WP'  :     32, #wh-pronoun who, what\n",
        "    'WP$' :     33, # possessive wh-pronoun whose\n",
        "    'WRB' :     34, # wh-abverb where, when\n",
        "    'PUNCT':    35, # Punctuations\n",
        "    'OTHER':    36, # Other syntax element\n",
        "    'PAD'  :    37, # Padding for syntax information\n",
        "    'SYM'  :    38,\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import time, re, string\n",
        "\n",
        "#%%############################################################################\n",
        "'''                        DATA GENERATOR WITH OTHER                        '''\n",
        "###############################################################################\n",
        "\n",
        "class data_generatorV3(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self,\n",
        "\n",
        "                 # DATA VARIABLES\n",
        "                 tokenizer, src_data, tgt_data = None,\n",
        "\n",
        "                 # TRAINING VARIABLES\n",
        "                 batch_size=64, shuffle = True, training = True,\n",
        "                 max_seq_len = None,\n",
        "\n",
        "                 # CONTROL TOKEN VARIABLES\n",
        "                 src_lan_id = 250004,\n",
        "                 tgt_lan_id = 250005,\n",
        "                 pad_id = 1,\n",
        "                 bos_id = 3,\n",
        "                 eos_id = 2,\n",
        "\n",
        "                 # VARIABLES FOR AVANCED TAGGING\n",
        "                 include_syntax = False,\n",
        "                 spacy_model = \"en_core_web_sm\",    # \"de_core_news_sm\"\n",
        "                 ):\n",
        "        assert len(src_data) == len(tgt_data), 'Source and target must have same length'\n",
        "        self.src_data = src_data\n",
        "        self.tgt_data = tgt_data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.training = training\n",
        "        self.include_syntax = include_syntax\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        #Setting special token values\n",
        "        self.src_lan_token = src_lan_id\n",
        "        self.tgt_lan_token = tgt_lan_id\n",
        "        self.bos_token = bos_id\n",
        "        self.eos_token = eos_id\n",
        "        self.pad_token = pad_id\n",
        "        self.control_tokens_list = [src_lan_id, tgt_lan_id, bos_id,\n",
        "                                    eos_id, pad_id, 0]\n",
        "\n",
        "        # PRECLEANING CORPUS - Deleting empty sentences\n",
        "        # self.src_data = [sen for sen in self.src_data if sen != '' and sen != ' ']\n",
        "        # if self.tgt_data != None:\n",
        "        #     self.tgt_data = [sen for sen in self.tgt_data if sen != '' and sen != ' ']\n",
        "        self.n_sentences = len(self.src_data)\n",
        "        self.len_ = int(np.ceil(self.n_sentences/batch_size))\n",
        "        self.indexes = np.arange(self.n_sentences)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # PREPROCESSING SOURCE SENTENCES\n",
        "        if self.include_syntax:\n",
        "            #src_pos_tags = ['    '*self.seq_length for i in range(self.n_sentences)]\n",
        "\n",
        "            src_dep_tags = ['    '*50 for i in range(self.n_sentences)]\n",
        "            src_tokens = [[1]*50 for i in range(self.n_sentences)]\n",
        "\n",
        "            sentence_counter = 0\n",
        "            import spacy\n",
        "            nlp = spacy.load(spacy_model)\n",
        "            to_disable = [com for com in nlp.component_names if com not in ['tok2vec', 'parser']]\n",
        "            for sen in self.src_data:\n",
        "                sen = self._prepare_sentence(sen)\n",
        "                with nlp.select_pipes(disable=to_disable):\n",
        "                    data = nlp(sen)\n",
        "                words = [t.text for t in data]\n",
        "\n",
        "\n",
        "                tokens = [self.tokenizer.tokenize(w) for w in words]\n",
        "                token_length = [len(t) for t in tokens]\n",
        "                src_tokens[sentence_counter] = [t for t_list in tokens for t in t_list]\n",
        "\n",
        "                dep = [[TAG_MAPPER[t.dep_]]*l for t, l in zip(data, token_length)]\n",
        "                src_dep_tags[sentence_counter] = [t for t_list in dep for t in t_list]\n",
        "                assert len(src_tokens[sentence_counter]) == len(src_dep_tags[sentence_counter])\n",
        "                sentence_counter += 1\n",
        "\n",
        "            self.src_dep_tags = src_dep_tags\n",
        "            self.src_tokens = src_tokens\n",
        "        else:\n",
        "            src_tokens = [[1]*50 for i in range(self.n_sentences)]\n",
        "            sentence_counter = 0\n",
        "            for sen in self.src_data:\n",
        "                sen = self._prepare_sentence(sen)\n",
        "                words = [w for w in sen.split(' ') if w != '']\n",
        "                tokens = [self.tokenizer.tokenize(w) for w in words]\n",
        "                src_tokens[sentence_counter] = [t for t_list in tokens for t in t_list]\n",
        "                sentence_counter += 1\n",
        "            self.src_tokens = src_tokens\n",
        "            self.src_dep_tags = None\n",
        "\n",
        "        # PREPROCESSING TARGET SENTENCES\n",
        "        if tgt_data != None:\n",
        "            tgt_tokens = [[1]*50 for i in range(self.n_sentences)]\n",
        "            sentence_counter = 0\n",
        "            for sen in self.tgt_data:\n",
        "                sen = self._prepare_sentence(sen)\n",
        "                words = [w for w in sen.split(' ') if w != '']\n",
        "                tokens = [self.tokenizer.tokenize(w) for w in words]\n",
        "                tgt_tokens[sentence_counter] = [t for t_list in tokens for t in t_list]\n",
        "                sentence_counter += 1\n",
        "            self.tgt_tokens = tgt_tokens\n",
        "\n",
        "\n",
        "\n",
        "    def _prepare_sentence(self, sentence):\n",
        "        # This function prepare the text for processing\n",
        "        sentence = re.sub('([.,!?()\\]\\[;])', r' \\1 ', sentence)\n",
        "        sentence = re.sub('\\s{2,}', ' ', sentence)\n",
        "        patterns1 = re.findall(r'(?<=\\|).+?(?=\\|)',\n",
        "                              re.sub('([0-9][\\s*][.,][\\s*][0-9])', r'|\\1|', sentence))\n",
        "\n",
        "        patterns2 = re.findall(r'(?<=\\|).+?(?=\\|)',\n",
        "                   re.sub('([a-z][\\s*][.][\\s*][a-z][\\s*][.])', r'|\\1|', sentence))\n",
        "\n",
        "        patterns = [patterns1[i] for i in range(0,len(patterns1),2)] + \\\n",
        "                    [patterns2[i] for i in range(0,len(patterns2),2)]\n",
        "\n",
        "        for pat in patterns:\n",
        "            sentence = sentence.replace(pat, pat.replace(\" \", \"\"))\n",
        "\n",
        "        return sentence\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index > self.len_-1:\n",
        "            raise IndexError()\n",
        "\n",
        "        if index == self.len_-1:\n",
        "            indexes = self.indexes[index*self.batch_size:]\n",
        "        else:\n",
        "            indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        src_ids = [self.src_tokens[i] for i in list(indexes)]\n",
        "\n",
        "        header = [self.bos_token, self.src_lan_token]\n",
        "        src_ids = [header+ids+[self.eos_token] for ids in src_ids]\n",
        "\n",
        "        max_length_src = max([len(ids) for ids in src_ids])\n",
        "        max_length_src = max_length_src if self.max_seq_len == None else min(self.max_seq_len,max_length_src)\n",
        "\n",
        "        att_mask = [[1]*len(ids)+[0]*(max_length_src-(len(ids))) for ids in src_ids]\n",
        "        src_ids = [ids+[self.pad_token]*(max_length_src-len(ids)) for ids in src_ids]\n",
        "        src_dep_tags = None\n",
        "\n",
        "        correct_none_lamb = lambda  x : x if x != None else 0\n",
        "        src_ids = [list(map(correct_none_lamb,i)) for i in src_ids]\n",
        "\n",
        "        if self.include_syntax:\n",
        "            src_dep_tags = [self.src_dep_tags[i] for i in list(indexes)]\n",
        "            src_dep_tags = [[SYNTAX_MAPPER['PAD'], SYNTAX_MAPPER['PAD']]+tags+[SYNTAX_MAPPER['PAD']]\n",
        "                            for tags in src_dep_tags]\n",
        "            src_dep_tags = [tags+[SYNTAX_MAPPER['PAD']]*(max_length_src-(len(tags))) for tags in src_dep_tags]\n",
        "\n",
        "\n",
        "        if self.training or self.tgt_data != None:\n",
        "            tgt_ids = [self.tgt_tokens[i] for i in list(indexes)]\n",
        "            header = [self.bos_token, self.tgt_lan_token]\n",
        "            tgt_ids = [header+ids+[self.eos_token] for ids in tgt_ids]\n",
        "\n",
        "            max_length_tgt = max([len(ids) for ids in tgt_ids]+[max_length_src])\n",
        "            max_length_tgt = max_length_tgt if self.max_seq_len == None else min(self.max_seq_len,max_length_tgt)\n",
        "\n",
        "\n",
        "            tgt_ids = [ids+[self.pad_token]*(max_length_tgt-len(ids))\n",
        "                       for ids in tgt_ids]\n",
        "            tgt_ids = [list(map(correct_none_lamb,i)) for i in tgt_ids]\n",
        "\n",
        "            src_ids = src_ids if max_length_src > max_length_tgt \\\n",
        "                        else [ids+[self.pad_token]*(max_length_tgt-len(ids)) for ids in src_ids]\n",
        "\n",
        "            att_mask = att_mask if max_length_src > max_length_tgt \\\n",
        "                        else [a+[0]*(max_length_tgt-max_length_src) for a in att_mask]\n",
        "\n",
        "            outputs = [tf.convert_to_tensor(src_ids, dtype = tf.int32),\n",
        "                        tf.convert_to_tensor(att_mask, dtype = tf.int32)]\n",
        "            if self.include_syntax:\n",
        "\n",
        "                src_dep_tags = src_dep_tags if max_length_src > max_length_tgt \\\n",
        "                        else [d+[SYNTAX_MAPPER['PAD']]*(max_length_tgt-max_length_src) for d in src_dep_tags]\n",
        "                outputs = outputs + [tf.convert_to_tensor(src_dep_tags, dtype = tf.int32)]\n",
        "            return outputs, tf.convert_to_tensor(tgt_ids)\n",
        "\n",
        "        else:\n",
        "            outputs = [tf.convert_to_tensor(src_ids, dtype = tf.int32),\n",
        "                       tf.convert_to_tensor(att_mask, dtype = tf.int32)]\n",
        "            if self.include_syntax:\n",
        "                outputs = outputs + [tf.convert_to_tensor(src_dep_tags, dtype = tf.int32)]\n",
        "            return outputs\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "    def detokenize(self, ids, clean = True):\n",
        "        if clean:\n",
        "            ids = [[int(i) for i in t if i not in self.control_tokens_list] for t in ids]\n",
        "        else:\n",
        "            ids = [[int(i) for i in t if i != self.pad_token] for t in ids]\n",
        "        return self.tokenizer.detokenize(ids)\n",
        "\n",
        "\n",
        "#%%############################################################################\n",
        "'''                              SPACY TAG GLOSSARY                         '''\n",
        "###############################################################################\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TEOzQCesvXNa",
        "outputId": "8741262e-58e5-4291-bd28-dff2929520f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                              SPACY TAG GLOSSARY                         '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer, AdamW, MarianConfig,get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "S1chfBUDuwvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exp_settings = {'WORKING_DIR': 'T2G_syntax', 'SRC_TRAIN_FILENAME': '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_sentences_train_lower_lemm_norm.txt', 'TGT_TRAIN_FILENAME': '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/train/phoenix_glosses_train_lower.txt', 'SRC_EVAL_FILENAME': '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower_lemm_norm.txt', 'TGT_EVAL_FILENAME': '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/dev/phoenix_glosses_dev_lower.txt',\n",
        "SRC_TOKEN = '<SPOK>'\n",
        "TGT_TOKEN =  '<GLOSS>'\n",
        "# SPACY_MODEL = 'de_core_news_sm'\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 1000\n",
        "LR = 1e-05\n",
        "VOCAB_SIZE = 3000\n",
        "SCALE_DOWN_FACTOR = 4\n",
        "EMBEDDING_DIM = 512\n",
        "N_TAG_TOKEN =  90\n",
        "\n",
        "TRAINED_MODEL_WEIGHTS = [str(i) for i in range(5,16, 5)] # EPOCHS FOR WHICH COMPUTE THE METRICS\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "GEN_SRC_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_lemm_norm.txt'\n",
        "GEN_TGT_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_glosses_test_lower.txt'\n",
        "# Initialize lists to store source and target sentences\n",
        "\n",
        "with open(GEN_SRC_FILENAME, 'rb') as f:\n",
        "    src_data = f.read().decode().split('\\n')\n",
        "N_SAMPLES_FOR_EXPERIMENT = len(src_data)\n",
        "with open(GEN_TGT_FILENAME, 'rb') as f:\n",
        "    tgt_data = f.read().decode().split('\\n')\n",
        "\n",
        "\n",
        "sp = spm.SentencePieceProcessor(model_file='/content/test_3000.model')\n",
        "\n",
        "eos_token = '<end>'\n",
        "bos_token = '<start>'\n",
        "pad_token = '<pad>'\n",
        "special_tokens = [bos_token, eos_token, pad_token,\n",
        "                  SRC_TOKEN, TGT_TOKEN]\n",
        "special_ids = [i[1] for i in sp.tokenize(special_tokens)]\n",
        "\n",
        "\n",
        "test_data_gen = data_generatorV3(sp, src_data, tgt_data = tgt_data,\n",
        "                 batch_size=BATCH_SIZE, shuffle = False, training = False,\n",
        "                 include_syntax = True,\n",
        "                 src_lan_id = special_ids[3],\n",
        "                 tgt_lan_id = special_ids[4],\n",
        "                 pad_id = special_ids[2],\n",
        "                 bos_id = special_ids[0],\n",
        "                 eos_id = special_ids[1])\n"
      ],
      "metadata": {
        "id": "FkTg7E-Tqy5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.mbart.modeling_tf_mbart import (TFMBartEncoder, TFMBartDecoder)"
      ],
      "metadata": {
        "id": "AIKXAtyexkKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFBertModel"
      ],
      "metadata": {
        "id": "5pVKlIMfJteS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFSharedEmbeddings, MBartConfig"
      ],
      "metadata": {
        "id": "_36TvZOlvpHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#%%############################################################################\n",
        "'''                        BeamHypotheses (from Huggingface)                '''\n",
        "###############################################################################\n",
        "\n",
        "class BeamHypotheses(object):\n",
        "    def __init__(self, num_beams, max_length, length_penalty, early_stopping):\n",
        "        \"\"\"\n",
        "        Initialize n-best list of hypotheses.\n",
        "        \"\"\"\n",
        "        self.max_length = max_length - 1  # ignoring bos_token\n",
        "        self.length_penalty = length_penalty\n",
        "        self.early_stopping = early_stopping\n",
        "        self.num_beams = num_beams\n",
        "        self.beams = []\n",
        "        self.worst_score = 1e9\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Number of hypotheses in the list.\n",
        "        \"\"\"\n",
        "        return len(self.beams)\n",
        "\n",
        "    def add(self, hyp, sum_logprobs):\n",
        "        \"\"\"\n",
        "        Add a new hypothesis to the list.\n",
        "        \"\"\"\n",
        "        score = sum_logprobs / len(hyp) ** self.length_penalty\n",
        "        if len(self) < self.num_beams or score > self.worst_score:\n",
        "            self.beams.append((score, hyp))\n",
        "            if len(self) > self.num_beams:\n",
        "                sorted_scores = sorted([(s, idx) for idx, (s, _) in enumerate(self.beams)])\n",
        "                del self.beams[sorted_scores[0][1]]\n",
        "                self.worst_score = sorted_scores[1][0]\n",
        "            else:\n",
        "                self.worst_score = min(score, self.worst_score)\n",
        "\n",
        "    def is_done(self, best_sum_logprobs, cur_len):\n",
        "        \"\"\"\n",
        "        If there are enough hypotheses and that none of the hypotheses being generated can become better than the worst\n",
        "        one in the heap, then we are done with this sentence.\n",
        "        \"\"\"\n",
        "\n",
        "        if len(self) < self.num_beams:\n",
        "            return False\n",
        "        elif self.early_stopping:\n",
        "            return True\n",
        "        else:\n",
        "            cur_score = best_sum_logprobs / cur_len ** self.length_penalty\n",
        "            ret = self.worst_score >= cur_score\n",
        "            return ret\n",
        "\n",
        "#%%############################################################################\n",
        "'''                      Useful Helpers   (from Huggingface)                '''\n",
        "###############################################################################\n",
        "\n",
        "def _reorder_cache(past, beam_idx):\n",
        "    if len(past) == 1:\n",
        "        return past\n",
        "\n",
        "    past_key_values = past[1]\n",
        "\n",
        "    reordered_past = ()\n",
        "    for layer_past_key_values in past_key_values:\n",
        "        reordered_past += (\n",
        "            tuple(tf.gather(layer_past_key_value, beam_idx) for layer_past_key_value in layer_past_key_values[:2])\n",
        "            + layer_past_key_values[2:],\n",
        "        )\n",
        "    return (past[0], reordered_past)\n",
        "\n",
        "\n",
        "def set_tensor_by_indices_to_value(tensor, indices, value):\n",
        "    # create value_tensor since tensor value assignment is not possible in TF\n",
        "    value_tensor = tf.zeros_like(tensor) + value\n",
        "    return tf.where(indices, value_tensor, tensor)\n",
        "\n",
        "def _create_next_token_logits_penalties(input_ids, logits, repetition_penalty):\n",
        "    # create logit penalties for already seen input_ids\n",
        "    token_penalties = np.ones(tf.shape(logits))\n",
        "    prev_input_ids = [np.unique(input_id) for input_id in input_ids.numpy()]\n",
        "    for i, prev_input_id in enumerate(prev_input_ids):\n",
        "        logit_penalized = logits[i].numpy()[prev_input_id]\n",
        "        logit_penalties = np.zeros(logit_penalized.shape)\n",
        "        # if previous logit score is < 0 then multiply repetition penalty else divide\n",
        "        logit_penalties[logit_penalized < 0] = repetition_penalty\n",
        "        logit_penalties[logit_penalized > 0] = 1 / repetition_penalty\n",
        "        np.put(token_penalties[i], prev_input_id, logit_penalties)\n",
        "    return tf.convert_to_tensor(token_penalties, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def _extend_tensors(tensor_list, batch_size, num_beams, input_seq_len):\n",
        "    extended_list = []\n",
        "    for t in tensor_list:\n",
        "        t = tf.broadcast_to(tf.expand_dims(t, 1),\n",
        "                            (batch_size, num_beams, input_seq_len))\n",
        "\n",
        "        t = tf.reshape(t, (batch_size * num_beams, input_seq_len))\n",
        "        extended_list.append(t)\n",
        "    return extended_list"
      ],
      "metadata": {
        "id": "DoT2MO5Qt_PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/config_architecture.dict', 'rb') as f:\n",
        "            config_dict = pickle.load(f)\n",
        "\n",
        "# UPDATING DICTIONARY VALUES\n",
        "mbarConfig_dict = MBartConfig(config_dict)\n",
        "\n",
        "mbarConfig_dict.vocab_size = VOCAB_SIZE\n",
        "mbarConfig_dict.d_model = EMBEDDING_DIM\n",
        "mbarConfig_dict.max_position_embeddings = EMBEDDING_DIM\n",
        "\n",
        "mbarConfig_dict.encoder_attention_heads  //=  SCALE_DOWN_FACTOR\n",
        "mbarConfig_dict.encoder_ffn_dim //= SCALE_DOWN_FACTOR\n",
        "mbarConfig_dict.encoder_layers //= SCALE_DOWN_FACTOR\n",
        "\n",
        "mbarConfig_dict.decoder_attention_heads //= SCALE_DOWN_FACTOR\n",
        "mbarConfig_dict.decoder_ffn_dim //= SCALE_DOWN_FACTOR\n",
        "mbarConfig_dict.decoder_layers //= SCALE_DOWN_FACTOR\n",
        "\n",
        "word_embedding_table = TFSharedEmbeddings(mbarConfig_dict.vocab_size, mbarConfig_dict.d_model)\n",
        "dep_embedding_table = TFSharedEmbeddings(N_TAG_TOKEN, mbarConfig_dict.d_model)\n",
        "\n",
        "encoder = TFMBartEncoder(mbarConfig_dict)\n",
        "decoder = TFMBartDecoder(mbarConfig_dict)\n",
        "\n",
        "word_emb = word_embedding_table(tf.expand_dims([1], -1))*32.0\n",
        "dep_emb = dep_embedding_table(tf.expand_dims([1], -1))*32.0\n",
        "\n",
        "enc_inputs_embeds = word_emb+dep_emb\n",
        "enc_hidden_states = encoder(input_ids = None,\n",
        "        inputs_embeds = enc_inputs_embeds, attention_mask=tf.expand_dims([1], -1))['last_hidden_state']\n",
        "dec_inputs_embeds = word_embedding_table(tf.expand_dims([1], -1))*32.0\n",
        "\n",
        "dec_hidden_states = decoder(input_ids=None,\n",
        "        inputs_embeds=dec_inputs_embeds,\n",
        "        encoder_hidden_states=enc_hidden_states,\n",
        "        encoder_attention_mask=tf.expand_dims([1], -1),\n",
        "        past_key_values=None,\n",
        "        use_cache=False,\n",
        "        training=False)\n",
        "\n",
        "\n",
        "#%%############################################################################\n",
        "'''              GENERATE_SEQ FUNCTION (MODIFIED FROM HUGGINGFACE)          '''\n",
        "###############################################################################\n",
        "# from transformers.generation_utils import BeamHypotheses, _reorder_cache, _create_next_token_logits_penalties, _extend_tensors, set_tensor_by_indices_to_value\n",
        "def beam_search_generation( enc_word_ids, enc_dep_ids, enc_input_att,\n",
        "                            target_lan_token_id = special_ids[4],\n",
        "                            pad_token_id = special_ids[2],\n",
        "                            bos_token_id = special_ids[0],\n",
        "                            eos_token_id = special_ids[1],\n",
        "\n",
        "                            num_beams = 5,\n",
        "                            early_stopping = True,\n",
        "                            length_penalty = 1.0,\n",
        "                            min_length= 0,\n",
        "                            max_length = 200,\n",
        "                            repetition_penalty = 1.0,\n",
        "                            temperature = 1.0):\n",
        "\n",
        "    ''' VARIABLE INITIALIZATION '''\n",
        "    batch_size = enc_word_ids.shape[0]\n",
        "    input_seq_len = int(tf.shape(enc_word_ids)[-1])\n",
        "    vocab_size = word_embedding_table.vocab_size\n",
        "\n",
        "    # TOKENS IDS INITIALIZATION\n",
        "    target_lan_token_id = SPECIAL_TOKEN_2_IDS[\"es_XX\"] if target_lan_token_id == None else target_lan_token_id\n",
        "    eos_token_id = SPECIAL_TOKEN_2_IDS['</s>'] if eos_token_id == None else eos_token_id\n",
        "    pad_token_id = SPECIAL_TOKEN_2_IDS['<pad>'] if pad_token_id == None else pad_token_id\n",
        "    bos_token_id = SPECIAL_TOKEN_2_IDS['</s>']  if bos_token_id == None else bos_token_id\n",
        "\n",
        "    ''' ENCODING INPUT TOKENS '''\n",
        "    encoder_embs = (word_embedding_table(enc_word_ids)+\n",
        "                                        dep_embedding_table(enc_dep_ids))*32.\n",
        "\n",
        "    encoder_outputs = encoder(None, inputs_embeds = encoder_embs,\n",
        "                              attention_mask=enc_input_att)\n",
        "\n",
        "    [enc_word_ids, enc_dep_ids, enc_input_att] = _extend_tensors([enc_word_ids, enc_dep_ids, enc_input_att], batch_size, num_beams, input_seq_len)\n",
        "\n",
        "\n",
        "    # expand batch_idx to assign correct encoder output for expanded input_ids (due to num_beams > 1 and num_return_sequences > 1)\n",
        "    expanded_batch_idxs = tf.reshape(\n",
        "        tf.repeat(tf.expand_dims(tf.range(batch_size), -1), repeats=num_beams , axis=1),\n",
        "        shape=(-1,),\n",
        "    )\n",
        "\n",
        "    # expand encoder_outputs\n",
        "    encoder_outputs = (tf.gather(encoder_outputs[0], expanded_batch_idxs, axis=0),)\n",
        "\n",
        "\n",
        "    # Generating Beam Hypothesis\n",
        "    generated_hyps = [\n",
        "        BeamHypotheses(num_beams, max_length, length_penalty, early_stopping=early_stopping)\n",
        "        for _ in range(batch_size)\n",
        "    ]\n",
        "\n",
        "    # for greedy decoding it is made sure that only tokens of the first beam are considered to avoid sampling the exact same tokens three times\n",
        "    beam_scores = tf.concat([tf.zeros((batch_size, 1), dtype=tf.float32),\n",
        "                             tf.ones((batch_size, num_beams - 1), dtype=tf.float32) * (-1e9)], -1)\n",
        "    beam_scores = tf.reshape(beam_scores, (batch_size * num_beams,))\n",
        "    # True when sentences are completely generated\n",
        "    done = [False for _ in range(batch_size)]\n",
        "\n",
        "\n",
        "    past = encoder_outputs\n",
        "    encoder_hidden_states=encoder_outputs[0]\n",
        "    encoder_attention_mask = enc_input_att\n",
        "    input_ids = (tf.ones((batch_size * num_beams, 1),\n",
        "                                 dtype=tf.int32)* bos_token_id)\n",
        "    past_key_values = None\n",
        "    cur_len = 1\n",
        "\n",
        "\n",
        "\n",
        "    while cur_len < max_length:\n",
        "\n",
        "        decoder_input_ids = tf.expand_dims(tf.gather(input_ids,cur_len-1,axis = -1), -1)\n",
        "        decoder_token_embs = word_embedding_table(decoder_input_ids)*32.0\n",
        "        outputs = decoder(None,\n",
        "                inputs_embeds=decoder_token_embs,\n",
        "                encoder_attention_mask=encoder_attention_mask,\n",
        "                encoder_hidden_states=encoder_hidden_states, #Deshacer Tuple?\n",
        "                return_dict = True,\n",
        "                past_key_values = past_key_values\n",
        "                )\n",
        "\n",
        "        logits = word_embedding_table(outputs[0], mode = 'linear')\n",
        "        next_token_logits = logits[:, -1, :]  # (batch_size * num_beams, vocab_size)\n",
        "        past = outputs[1]\n",
        "\n",
        "\n",
        "        ''' SETTING EOS AND BOS TOKENS & APPLYING PENALTIES (ADJUSTING LOGITS) '''\n",
        "        if repetition_penalty != 1.0:\n",
        "            next_token_logits_penalties = _create_next_token_logits_penalties(\n",
        "                input_ids, next_token_logits, repetition_penalty\n",
        "            )\n",
        "            next_token_logits = tf.math.multiply(next_token_logits, next_token_logits_penalties)\n",
        "\n",
        "        if temperature != 1.0:\n",
        "            next_token_logits = next_token_logits / temperature\n",
        "\n",
        "        # ADJUSTING LOGITS\n",
        "        if cur_len == 1:\n",
        "            vocab_range = tf.constant(range(vocab_size))\n",
        "            next_token_logits = tf.where(vocab_range != target_lan_token_id, -1e8, next_token_logits)\n",
        "        elif cur_len == max_length - 1:\n",
        "            vocab_range = tf.constant(range(vocab_size))\n",
        "            next_token_logits = tf.where(vocab_range != eos_token_id, -1e8, next_token_logits)\n",
        "\n",
        "\n",
        "\n",
        "        #calculate log softmax score\n",
        "        scores = tf.nn.log_softmax(next_token_logits, axis=-1)  # (batch_size * num_beams, vocab_size)\n",
        "        # set eos token prob to zero if min_length is not reached\n",
        "        if cur_len < min_length:\n",
        "            # create eos_token_id boolean mask\n",
        "            num_batch_hypotheses = batch_size * num_beams\n",
        "\n",
        "            is_token_logit_eos_token = tf.convert_to_tensor(\n",
        "                [True if token is eos_token_id else False for token in range(vocab_size)], dtype=tf.bool\n",
        "            )\n",
        "            eos_token_indices_mask = tf.broadcast_to(is_token_logit_eos_token, [num_batch_hypotheses, vocab_size])\n",
        "            scores = set_tensor_by_indices_to_value(scores, eos_token_indices_mask, -float(\"inf\"))\n",
        "\n",
        "        # if do_sample == False\n",
        "        # Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)\n",
        "        next_scores = scores + tf.broadcast_to(\n",
        "            beam_scores[:, None], (batch_size * num_beams, vocab_size)\n",
        "        )  # (batch_size * num_beams, vocab_size)\n",
        "\n",
        "        # re-organize to group the beam together (we are keeping top hypothesis across beams)\n",
        "        next_scores = tf.reshape(\n",
        "            next_scores, (batch_size, num_beams * vocab_size)\n",
        "        )  # (batch_size, num_beams * vocab_size)\n",
        "\n",
        "        next_scores, next_tokens = tf.math.top_k(next_scores, k=2 * num_beams, sorted=True)\n",
        "\n",
        "        # next batch beam content\n",
        "        next_batch_beam = []\n",
        "\n",
        "        # for each sentence create the possible Hyposthesis\n",
        "        for batch_idx in range(batch_size):\n",
        "\n",
        "            # if we are done with this sentence\n",
        "            if done[batch_idx]:\n",
        "                next_batch_beam.extend([(0, pad_token_id, 0)] * num_beams)  # pad the batch\n",
        "                continue\n",
        "\n",
        "            # next sentence beam content\n",
        "            next_sent_beam = []\n",
        "\n",
        "            # next tokens for this sentence\n",
        "            for beam_token_rank, (beam_token_id, beam_token_score) in enumerate(\n",
        "                zip(next_tokens[batch_idx], next_scores[batch_idx])):\n",
        "\n",
        "                # get beam and token IDs\n",
        "                beam_id = beam_token_id // vocab_size\n",
        "                token_id = beam_token_id % vocab_size\n",
        "\n",
        "                effective_beam_id = batch_idx * num_beams + beam_id\n",
        "                # add to generated hypotheses if end of sentence or last iteration\n",
        "                if (eos_token_id is not None) and (token_id.numpy() == eos_token_id):\n",
        "                    # if beam_token does not belong to top num_beams tokens, it should not be added\n",
        "                    is_beam_token_worse_than_top_num_beams = beam_token_rank >= num_beams\n",
        "                    if is_beam_token_worse_than_top_num_beams:\n",
        "                        continue\n",
        "                    generated_hyps[batch_idx].add(\n",
        "                        tf.identity(input_ids[effective_beam_id]), beam_token_score.numpy()\n",
        "                    )\n",
        "                else:\n",
        "                    # add next predicted token if it is not eos_token\n",
        "                    next_sent_beam.append((beam_token_score, token_id, effective_beam_id))\n",
        "\n",
        "                # the beam for next step is full\n",
        "                if len(next_sent_beam) == num_beams:\n",
        "                    break\n",
        "            # Check if we are done so that we can save a pad step if all(done)\n",
        "            done[batch_idx] = done[batch_idx] or generated_hyps[batch_idx].is_done(\n",
        "                tf.reduce_max(next_scores[batch_idx]).numpy(), cur_len\n",
        "            )\n",
        "            # update next beam content\n",
        "            next_batch_beam.extend(next_sent_beam)\n",
        "\n",
        "        # stop when we are done with each sentence\n",
        "        if all(done):\n",
        "            break\n",
        "\n",
        "        beam_scores = tf.convert_to_tensor([x[0] for x in next_batch_beam], dtype=tf.float32)\n",
        "        beam_tokens = tf.convert_to_tensor([x[1] for x in next_batch_beam], dtype=tf.int32)\n",
        "        beam_idx = tf.convert_to_tensor([x[2] for x in next_batch_beam], dtype=tf.int32)\n",
        "\n",
        "        # re-order batch and update current length\n",
        "        input_ids = tf.stack([tf.identity(input_ids[x, :]) for x in beam_idx])\n",
        "        input_ids = tf.concat([input_ids, tf.expand_dims(beam_tokens, 1)], axis=-1)\n",
        "        # re-order internal states & Initialize next forward values\n",
        "        encoder_outputs, past_key_values = _reorder_cache(past, beam_idx)\n",
        "        cur_len += 1\n",
        "\n",
        "\n",
        "\n",
        "    ''' FINILAZING GENERATION '''\n",
        "    # finalize all open beam hypotheses and end to generated hypotheses\n",
        "    for batch_idx in range(batch_size):\n",
        "        # Add all open beam hypothesis to generated_hyps\n",
        "        if done[batch_idx]:\n",
        "            continue\n",
        "        # test that beam scores match previously calculated scores if not eos and batch_idx not done\n",
        "        if eos_token_id is not None and all(\n",
        "            (token_id % vocab_size).numpy().item() != eos_token_id for token_id in next_tokens[batch_idx]\n",
        "        ):\n",
        "            assert tf.reduce_all(\n",
        "                next_scores[batch_idx, :num_beams] == tf.reshape(beam_scores, (batch_size, num_beams))[batch_idx]\n",
        "            ), \"If batch_idx is not done, final next scores: {} have to equal to accumulated beam_scores: {}\".format(\n",
        "                next_scores[:, :num_beams][batch_idx], tf.reshape(beam_scores, (batch_size, num_beams))[batch_idx]\n",
        "            )\n",
        "\n",
        "        # need to add best num_beams hypotheses to generated hyps\n",
        "        for beam_id in range(num_beams):\n",
        "            effective_beam_id = batch_idx * num_beams + beam_id\n",
        "            final_score = beam_scores[effective_beam_id].numpy().item()\n",
        "            final_tokens = input_ids[effective_beam_id]\n",
        "            generated_hyps[batch_idx].add(final_tokens, final_score)\n",
        "\n",
        "    # select the best hypotheses\n",
        "    sent_lengths_list = []\n",
        "    best = []\n",
        "\n",
        "    # retrieve best hypotheses\n",
        "    for i, hypotheses in enumerate(generated_hyps):\n",
        "        sorted_hyps = sorted(hypotheses.beams, key=lambda x: x[0])\n",
        "        best_hyp = sorted_hyps.pop()[1]\n",
        "        sent_lengths_list.append(len(best_hyp))\n",
        "        best.append(best_hyp)\n",
        "\n",
        "\n",
        "    sent_lengths = tf.convert_to_tensor(sent_lengths_list, dtype=tf.int32)\n",
        "\n",
        "    # shorter batches are filled with pad_token\n",
        "    if tf.reduce_min(sent_lengths).numpy() != tf.reduce_max(sent_lengths).numpy():\n",
        "        sent_max_len = min(tf.reduce_max(sent_lengths).numpy() + 1, max_length)\n",
        "        decoded_list = []\n",
        "\n",
        "        # fill with hypothesis and eos_token_id if necessary\n",
        "        for i, hypo in enumerate(best):\n",
        "            # if sent_length is max_len do not pad\n",
        "            if sent_lengths[i] == sent_max_len:\n",
        "                decoded_slice = hypo\n",
        "            else:\n",
        "                # else pad to sent_max_len\n",
        "                num_pad_tokens = sent_max_len - sent_lengths[i]\n",
        "                padding = pad_token_id * tf.ones((num_pad_tokens,), dtype=tf.int32)\n",
        "                decoded_slice = tf.concat([hypo, padding], axis=-1)\n",
        "\n",
        "                # finish sentence with EOS token\n",
        "                if sent_lengths[i] < max_length:\n",
        "                    decoded_slice = tf.where(\n",
        "                        tf.range(sent_max_len, dtype=tf.int32) == sent_lengths[i],\n",
        "                        eos_token_id * tf.ones((sent_max_len,), dtype=tf.int32),\n",
        "                        decoded_slice,\n",
        "                    )\n",
        "            # add to list\n",
        "            decoded_list.append(decoded_slice)\n",
        "\n",
        "        decoded = tf.stack(decoded_list)\n",
        "    else:\n",
        "        # none of the hypotheses have an eos_token\n",
        "        decoded = tf.stack(best)\n",
        "    return decoded\n",
        "\n",
        "\n",
        "\n",
        "#%%############################################################################\n",
        "'''                            GENERATION PROCESS                           '''\n",
        "###############################################################################\n",
        "\n",
        "for m in TRAINED_MODEL_WEIGHTS:\n",
        "    # Finetuned\n",
        "    with open('/content/encoder_125.weights'.format(m),'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    encoder.set_weights(weights)\n",
        "\n",
        "    with open('/content/decoder_125.weights'.format(m),'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    decoder.set_weights(weights)\n",
        "\n",
        "    with open('/content/word_embeddings_125.weights'.format(m),'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    word_embedding_table.set_weights(weights)\n",
        "\n",
        "    with open('/content/dep_embeddings_125.weights'.format(m),'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    dep_embedding_table.set_weights(weights)\n",
        "\n",
        "    generated_text = ['  '*20 for _ in range(test_data_gen.n_sentences)]\n",
        "    sentence_counter = 0\n",
        "    t0 = time.time()\n",
        "    for i in range(len(test_data_gen)):\n",
        "        tf.print('Generation Batch {}/{}'.format(i+1, len(test_data_gen)))\n",
        "\n",
        "        (enc_word_ids,enc_input_att, enc_dep_ids), dec_input_ids  = test_data_gen[i]\n",
        "        generated_tokens = beam_search_generation(enc_word_ids, enc_dep_ids, enc_input_att)\n",
        "        n_gen_sentences = generated_tokens.shape[0]\n",
        "\n",
        "        generated_text[sentence_counter:sentence_counter+n_gen_sentences] = test_data_gen.detokenize(generated_tokens, clean=True)\n",
        "        sentence_counter += n_gen_sentences\n",
        "    gen_time = time.time()-t0\n",
        "    tf.print('Elapsed Time: {}'.format(gen_time))\n",
        "    with open('/content/generated_text2.txt'.format(m), 'w', encoding = 'utf-8') as f:\n",
        "        f.write('\\n'.join(generated_text))\n"
      ],
      "metadata": {
        "id": "vfQB1Bh6LVeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "cz_JBW0gQY6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEN_SRC_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_sentences_test_lower_lemm_norm.txt'\n",
        "GEN_TGT_FILENAME='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_glosses_test_lower.txt'"
      ],
      "metadata": {
        "id": "B4xPVo_XVF_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys\n",
        "sys.path.insert(0, \"./utils/\")\n",
        "\n",
        "# from rouge import rouge\n",
        "# from sacreBLEU_script import compute_sacre_bleu\n",
        "\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "# from pyter import ter\n",
        "\n",
        "REF_FILENAME = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation-main/Data/t2g_phoenix/test/phoenix_test_glosses.txt'\n",
        "WORKING_DIR = 'T2G_syntax' # 'T2G_no_syntax'\n",
        "EVAL_EPOCHS = range(5,501,5)\n",
        "\n",
        "\n",
        "#%%############################################################################\n",
        "'''                         ACCOMODATING ES-EN DATA                         '''\n",
        "###############################################################################\n",
        "\n",
        "with open(REF_FILENAME, 'rb') as f:\n",
        "    ref_data = f.read().decode().split('\\n')\n",
        "\n",
        "columns = ['Sacrebleu']\n",
        "\n",
        "#%%############################################################################\n",
        "'''                            COMPUTING METRICS                            '''\n",
        "###############################################################################\n",
        "results_top_container = np.zeros(shape = (len(EVAL_EPOCHS), len(columns)))\n",
        "imodel = 0\n",
        "for it in EVAL_EPOCHS:\n",
        "\n",
        "    with open('/content/125.txt'.format(it), 'rb') as f:\n",
        "        generated_text = f.read().decode()\n",
        "        generated_text = [s.strip() for s in generated_text.split('\\n')]\n",
        "\n",
        "    hyp = [s for s in generated_text]\n",
        "    ref = [s for s in ref_data]\n",
        "\n",
        "    try:\n",
        "      results_top_container[imodel, 0] = compute_sacre_bleu(hyp, ref, tokenize = 'char')\n",
        "    except EOFError:\n",
        "      results_top_container[imodel, 0] = 0\n",
        "\n",
        "    imodel += 1\n",
        "\n",
        "results = pd.DataFrame(results_top_container, columns = columns, index =EVAL_EPOCHS)\n",
        "dataset_type = REF_FILENAME.split('_')[-1].split('.')[0]\n",
        "# results.to_excel('{}/metrics_{}.xlsx'.format(WORKING_DIR, dataset_type))\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7OSwfrpcQA9F",
        "outputId": "94882068-29fb-4fd3-994e-eabd88ccadd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sacrebleu\n",
              "5    51.447696\n",
              "10   51.447696\n",
              "15   51.447696\n",
              "20   51.447696\n",
              "25   51.447696\n",
              "..         ...\n",
              "480  51.447696\n",
              "485  51.447696\n",
              "490  51.447696\n",
              "495  51.447696\n",
              "500  51.447696\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8ae85f8-a019-474b-b808-bfc8715a7ec4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sacrebleu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>51.447696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8ae85f8-a019-474b-b808-bfc8715a7ec4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8ae85f8-a019-474b-b808-bfc8715a7ec4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8ae85f8-a019-474b-b808-bfc8715a7ec4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8f189a7-2c6d-46db-85e4-4262298960dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8f189a7-2c6d-46db-85e4-4262298960dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8f189a7-2c6d-46db-85e4-4262298960dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paraphrasing"
      ],
      "metadata": {
        "id": "GoBONfcZxXQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def my_paraphrase(sentence):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
        "    text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "    encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "    input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids, attention_mask=attention_masks,\n",
        "        max_length=256,\n",
        "        do_sample=True,\n",
        "        top_k=120,\n",
        "        top_p=0.95,\n",
        "        early_stopping=False,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "\n",
        "    for output in outputs:\n",
        "        line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "\n",
        "    return line\n",
        "with open('converted_sentences.txt', 'r') as f:\n",
        "  for sentence in (lines):\n",
        "    translated_sentence=(GoogleTranslator(source='auto', target='en').translate(sentence))\n",
        "    para=(my_paraphrase(translated_sentence))\n",
        "    translated_para=(GoogleTranslator(source='auto', target='ge').translate(sentence))\n",
        "    f.write(translated_para+\"\\n\")\n"
      ],
      "metadata": {
        "id": "CwZZoL7KsrB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to your source and target files\n",
        "source_file_path_train = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation/Data/t2g_phoenix/train/phoenix_sentences_train_lower.txt'\n",
        "target_file_path_train = '/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation/Data/t2g_phoenix/train/phoenix_glosses_train_lower.txt'\n",
        "\n",
        "source_file_path_valid='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation/Data/t2g_phoenix/dev/phoenix_sentences_dev_lower.txt'\n",
        "target_file_path_valid='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation/Data/t2g_phoenix/dev/phoenix_glosses_dev_lower.txt'\n",
        "\n",
        "source_file_path_test='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation/Data/t2g_phoenix/test/phoenix_sentences_test_lower.txt'\n",
        "target_file_path_test='/content/text-to-gloss-sign-language-translation-main/text-to-gloss-sign-language-translation/Data/t2g_phoenix/test/phoenix_glosses_test_lower.txt'\n",
        "# Initialize lists to store source and target sentences\n"
      ],
      "metadata": {
        "id": "ds3aWiorxXQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_train, 'r') as file:\n",
        "    train_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_train, 'r') as file:\n",
        "    train_dataset_tgt = file.readlines()"
      ],
      "metadata": {
        "id": "UTFw92XvxXQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_backtag_train = '/content/converted_sentences.txt'"
      ],
      "metadata": {
        "id": "FywPQ6kGxXQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_train, 'r') as file:\n",
        "    train_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_train, 'r') as file:\n",
        "    train_dataset_tgt = file.readlines()\n",
        "\n",
        "with open(src_backtag_train, 'r') as file:\n",
        "    train_backtag_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_train, 'r') as file:\n",
        "    train_backtag_tgt = file.readlines()\n",
        "\n",
        "train_dataset_src = train_dataset_src+ train_backtag_src\n",
        "train_dataset_tgt = train_dataset_tgt+ train_backtag_tgt\n",
        "\n",
        "\n",
        "print(len(train_dataset_src),\" \", len(train_dataset_tgt))\n",
        "print(train_dataset_src[0],\"--> \", train_dataset_tgt[0])\n",
        "print(train_dataset_src[7096],\"--> \", train_dataset_tgt[7096])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801d389b-42ff-4c65-9316-dcd5dc2adee3",
        "id": "NyZn58bzxXQH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14192   14192\n",
            "und nun die wettervorhersage für morgen donnerstag den zwölften august\n",
            " -->  jetzt wetter morgen donnerstag zwoelf februar\n",
            "\n",
            "... and now the Wettervorhersage for morgen - Donnerstag from December twelve - August.\n",
            " -->  jetzt wetter morgen donnerstag zwoelf februar\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_valid, 'r') as file:\n",
        "    valid_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_valid, 'r') as file:\n",
        "    valid_dataset_tgt = file.readlines()"
      ],
      "metadata": {
        "id": "GnAKX5trxXQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset_src[1])\n",
        "print(train_dataset_tgt[1])\n",
        "print(len(train_dataset_src), len(train_dataset_tgt))\n",
        "print(len(valid_dataset_src), len(valid_dataset_tgt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376cbc1a-e19a-4396-cc3e-7abc2d30e966",
        "id": "7xqwcUfpxXQI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mancherorts regnet es auch länger und ergiebig auch lokale überschwemmungen sind wieder möglich\n",
            "\n",
            "ort regen durch regen koennen ueberschwemmung koennen\n",
            "\n",
            "14192 14192\n",
            "519 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "08uSdwGMxXQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model name\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-de'  # Replace with your desired Marian model\n",
        "\n",
        "sentencepiece_options = \"model_type=bpe,vocab_size=2000\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name, additional_special_tokens=[\"<s>\", \"</s>\", \"<pad>\", \"<unk>\"], sentencepiece_options=sentencepiece_options)\n",
        "tokenizer.model_max_length = 512  # Adjust as needed\n",
        "\n",
        "# Apply additional configurations\n",
        "config = MarianConfig.from_pretrained(model_name)\n",
        "config.layer_norm = True  # Set layer normalization to True\n",
        "config.dim_emb = 512\n",
        "config.transformer_dim_ffn = 2048\n",
        "config.transformer_heads = 8\n",
        "config.transformer_ffn_activation = \"relu\"\n",
        "config.enc_depth = 1\n",
        "config.dec_depth = 2\n",
        "config.enc_cell = \"lstm\"\n",
        "config.enc_cell_depth = 2\n",
        "config.dec_cell_base_depth = 2\n",
        "config.dec_cell = \"lstm\"\n",
        "config.sync_sgd = True\n",
        "config.dropout_src = 0.1\n",
        "config.dropout_trg = 0.1\n",
        "config.optimizer_params = [0.9, 0.98, 1e-09]\n",
        "config.clip_norm = 5\n",
        "config.beam_size = 6\n",
        "config.normalize = 0.6\n",
        "config.exponential_smoothing = True\n",
        "config.seed = 1111\n",
        "config.tied_embeddings_all = True\n",
        "config.transformer_dropout = 0.1\n",
        "config.label_smoothing = 0.1\n",
        "\n",
        "# Load the model with modified tokenizer\n",
        "model = MarianMTModel.from_pretrained(model_name, config=config)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "80a2239258df40f280adc1b1145d7a67",
            "5b722979051c4629b6f429e0ac3e5345",
            "4fd7b3a046574f548cea133554f9a6ae",
            "f1459e100ea5480688bda4d92127c0cb",
            "b48621140e784941865d01a4e3d14305",
            "bbb9bbca5fcb48ad867fbe9ff534cb8f",
            "2f39bb72358c49ae961e4809dc2ce9ce",
            "0ca67ecec54843f8a7288f82cf33b132",
            "7e4578ed09ae4aa6a67a30c07e76ebad",
            "b10f7828195b4b0c8842fbb0262ff2ab",
            "48eae04b62604065b3a63a62d5b84dd7",
            "7bc983aa3bc2427b9f6fbe1a88c1c9b0",
            "2790b365583447fabb14c6e948b859d3",
            "ec1c3570add74ca5a34067596cdc696d",
            "24ad49ec6aea4829bb0c619688d56df5",
            "ffd5531a44d649e698c5ffacc24ec658",
            "d3e2d5974c374a7582ce8e1aff94c952",
            "d4bfe2e6ad5c4d0995eec58aa064dfe6",
            "ed026488059147349c3d50c473deac78",
            "f044babf985341a19c5aedab88b6b01f",
            "a56ca000ad4c456cbbe278b966233e45",
            "3f43dff97caa48b0ba263f5311eadd21",
            "fa49ad7a7eb7431fa3eec1eb9a20ace3",
            "5b83785a528240ac9ffbfea4d3c1e04f",
            "d9d46e59550d4bb197b7473942b38989",
            "3982e73a2fe849d1af642d577bab0330",
            "95ca2f6afb2f46aea4ef2012a39c2dcb",
            "513ea721e57c4d28bcaa2b2a494f4215",
            "aa58860adfa540bdb592530047ffdc82",
            "1562b81f051541c881b9dfc94d9fcd5f",
            "b99b31306d044d458a81af97f0a4a4ac",
            "01e5f71269934b41b71b1abd816bb53c",
            "258eee0957944fe8b295ae69b5bfbe66",
            "92e1c4f36610465f98082c65dd4827d4",
            "a27698b0f06f4bdbbb858efd201c416e",
            "061fed84c0994d1c93cf45f52cbcfb84",
            "b97726f7a42e453188ebe2cfe3b1f475",
            "971e3933177f42589d8ad5052327cf35",
            "ba443edb82f4473dad157e7929f4afc6",
            "254634cfbcbf430a9b6c0bba3525c840",
            "3cf9250019cb48ada0fa0a071dd4217b",
            "f73d5c46c91c4cacb542f6a710c20cd6",
            "f45b4882d50e4b5195769d311bf40b09",
            "5b011203caa641bd8522146cda467a6b",
            "fe5c73c28e334e91b6124eaf9bc470b7",
            "60f9e30e7bf64f94a5677cf250fff867",
            "824246cdbce641bcbb4a3a82ccfccbb8",
            "d409054223bf408a8726493cf1acbbd6",
            "36d51b37f5334074adbb232acbf98eee",
            "45956df0a4ae4ab5900da59dcc1ccdda",
            "9d9c0112c970473d9002e5ceac17320d",
            "f20dcd26c3d74b3c8e1d7697874c5923",
            "aa5c84c3ca154abd856e0b0e09fe8a51",
            "9e8d53cee8414a2e9bd43f5cccc20686",
            "a822d4b6052544699a113c11526c61f0",
            "635de639ce684be2b270c406a9e9d818",
            "7de5a4613e85429c97704816d606ee28",
            "880b92d0115a4af8b29e11cd2d001984",
            "ff4bccb9a8b94a09bd5ec215bad34f18",
            "4f848e0a690b4266a055e603ad11b079",
            "a1130caa4c5c4533b55994dc8ed5168d",
            "56da02ce2450400e8f6f7658793e4ca0",
            "16e35d7e06bd4ae891aa07af96c2cb79",
            "dfcf509f4bf3474197fa5d7feb37daa6",
            "8b1b67adcbac44a6b60f6317bcea4fcf",
            "d5b53b69f41743ae9cac444e30d188c6",
            "34d5c68d904142ac99e92a344531c5da",
            "33d0b6714da94f4dbb5df881aca2b6d6",
            "8f26d16c619a4c6385b9f611540b2e28",
            "d39bd2d47bea4d4f8cc5e0897243c62b",
            "d37c5ab2f69f4e30bb132929fac0a904",
            "dcbf926580334b109b69fce4bf81efec",
            "4a85ae7146514915bee475289f0b6ee9",
            "c33d2b95fbe9447981c5b1c4d0fc52e6",
            "fe1dd3d3ce0f45c99d799fb589643026",
            "6953a8c3245d47bd9bb5df385eb4c3f0",
            "32c71098448547d7b7e8179173a6f573"
          ]
        },
        "outputId": "f123ea72-4623-4177-9467-dbc25fe4e95e",
        "id": "WxspZafcxXQJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80a2239258df40f280adc1b1145d7a67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bc983aa3bc2427b9f6fbe1a88c1c9b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa49ad7a7eb7431fa3eec1eb9a20ace3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92e1c4f36610465f98082c65dd4827d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe5c73c28e334e91b6124eaf9bc470b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "635de639ce684be2b270c406a9e9d818"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34d5c68d904142ac99e92a344531c5da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(58102, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_texts = train_dataset_src\n",
        "target_texts = train_dataset_tgt\n",
        "\n",
        "source_texts_val = valid_dataset_src\n",
        "target_texts_val = valid_dataset_tgt"
      ],
      "metadata": {
        "id": "BWAKpgL6xXQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(source_texts[1])\n",
        "print(target_texts[1])\n",
        "print(len(source_texts), len(target_texts))\n",
        "print(len(source_texts_val), len(target_texts_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cfe0e2-fa41-4f97-a47b-2bc89e58a139",
        "id": "F86ijuGHxXQK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mancherorts regnet es auch länger und ergiebig auch lokale überschwemmungen sind wieder möglich\n",
            "\n",
            "ort regen durch regen koennen ueberschwemmung koennen\n",
            "\n",
            "14192 14192\n",
            "519 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize source and target sentences\n",
        "tokenized_data_train = tokenizer(source_texts, text_target=target_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_train = tokenized_data_train['input_ids']\n",
        "attention_mask_train = tokenized_data_train['attention_mask']\n",
        "labels_train = tokenized_data_train['labels']\n",
        "\n",
        "tokenized_data_valid = tokenizer(source_texts_val, text_target=target_texts_val, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_valid = tokenized_data_valid['input_ids']\n",
        "attention_mask_valid = tokenized_data_valid['attention_mask']\n",
        "labels_valid = tokenized_data_valid['labels']\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "train_dataset = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(input_ids_valid, attention_mask_valid, labels_valid)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "id": "x6kBqgjbxXQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sacrebleu import corpus_bleu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "num_epochs = 4\n",
        "warmup_steps = 16000  # Number of warmup steps\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    references = []  # To store actual target sentences\n",
        "    translations = []  # To store translated sentences\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            val_input_ids, val_attention_mask, val_labels = [val_b.to(device) for val_b in val_batch]\n",
        "\n",
        "            val_outputs = model.generate(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
        "            decoded_outputs = tokenizer.batch_decode(val_outputs, skip_special_tokens=True)\n",
        "\n",
        "            # Append actual target sentences and translations\n",
        "            references.extend([tokenizer.decode(t, skip_special_tokens=True) for t in val_labels.cpu().numpy()])\n",
        "            translations.extend(decoded_outputs)\n",
        "    # Compute BLEU score\n",
        "    bleu_score = corpus_bleu(translations,[references])\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation BLEU Score: {bleu_score.score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b0780a-37e2-4d6e-bc75-467e8efb8e95",
        "id": "z42OHar3xXQL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/4] - Average Loss: 1.3975\n",
            "Epoch [1/4] - Validation BLEU Score: 7.88\n",
            "Epoch [2/4] - Average Loss: 0.4953\n",
            "Epoch [2/4] - Validation BLEU Score: 19.48\n",
            "Epoch [3/4] - Average Loss: 0.4042\n",
            "Epoch [3/4] - Validation BLEU Score: 25.65\n",
            "Epoch [4/4] - Average Loss: 0.3534\n",
            "Epoch [4/4] - Validation BLEU Score: 25.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataset"
      ],
      "metadata": {
        "id": "KxrGSwPYxXQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_path_test, 'r') as file:\n",
        "    test_dataset_src = file.readlines()\n",
        "\n",
        "with open(target_file_path_test, 'r') as file:\n",
        "    test_dataset_tgt = file.readlines()\n",
        "\n",
        "\n",
        "tokenized_data_test = tokenizer(test_dataset_src, text_target=test_dataset_tgt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input_ids_test = tokenized_data_test['input_ids']\n",
        "attention_mask_test = tokenized_data_test['attention_mask']\n",
        "labels_test = tokenized_data_test['labels']\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "test_dataset = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "model.eval()\n",
        "references_test = []  # To store actual target sentences for the test set\n",
        "translations_test = []  # To store translated sentences for the test set\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_batch in test_loader:\n",
        "        test_input_ids, test_attention_mask, test_labels = [test_b.to(device) for test_b in test_batch]\n",
        "\n",
        "        test_outputs = model.generate(input_ids=test_input_ids, attention_mask=test_attention_mask)\n",
        "        decoded_test_outputs = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)\n",
        "\n",
        "        # Append actual target sentences and translations for the test set\n",
        "        references_test.extend([tokenizer.decode(t, skip_special_tokens=True) for t in test_labels.cpu().numpy()])\n",
        "        translations_test.extend(decoded_test_outputs)\n",
        "\n",
        "# Compute BLEU score for the test dataset\n",
        "bleu_score_test = corpus_bleu(translations_test,[references_test])\n",
        "print(f\"Test BLEU Score: {bleu_score_test.score :.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs6M5NxBhfwv",
        "outputId": "f71e277e-3ae4-4111-a16b-290ce1846c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test BLEU Score: 24.86\n"
          ]
        }
      ]
    }
  ]
}